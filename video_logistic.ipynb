{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from preprocess import get_records, preprocess_for_logistic, read_records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read and preprocess training and validation dataset for average pool, validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 23:37:45.837740: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "r = re.compile(\"^train.+\\\\.tfrecord$\")\n",
    "train_dir  = \"/Users/shufanxia/Documents/frame-level/\"\n",
    "val_dir = \"/Users/shufanxia/Documents/validate-frame/\"\n",
    "test_dir = \"/Users/shufanxia/Documents/test-frame/\"\n",
    "frames_train = get_records(train_dir,\"train\")\n",
    "frames_val = get_records(val_dir,\"validate\")\n",
    "frames_test = get_records(test_dir,\"validate\") # we reserve one validation frame record for test\n",
    "\n",
    "n_labels = 1000\n",
    "feat_rgb,feat_audio,feat_pseudoid,feat_labels = read_records(frames_train)\n",
    "X_rgb_train, X_audio_train,y_train = preprocess_for_logistic(feat_rgb,feat_audio,feat_labels,n_labels)\n",
    "\n",
    "feat_rgb_val,feat_audio_val,feat_pseudoid_val,feat_labels_val = read_records(frames_val)\n",
    "X_rgb_val, X_audio_val,y_val = preprocess_for_logistic(feat_rgb_val,feat_audio_val,feat_labels_val,n_labels)\n",
    "\n",
    "feat_rgb_test,feat_audio_test,feat_pseudoid_test,feat_labels_test = read_records(frames_test)\n",
    "X_rgb_test, X_audio_test,y_test = preprocess_for_logistic(feat_rgb_test,feat_audio_test,feat_labels_test,n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline logsitic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_logistic(input_type = \"rgb\",X_rgb_train=None,X_audio_train = None, y_train=None,\n",
    "                     X_rgb_val=None,X_audio_val= None,y_val=None):\n",
    "    # build and train a one vs all multiclass classifier\n",
    "    # choose from three types of inputs\n",
    "    if input_type == \"rgb\":\n",
    "        X_train = X_rgb_train\n",
    "        X_val = X_rgb_val\n",
    "    elif input_type == \"audio\":\n",
    "        X_train = X_audio_train\n",
    "        X_val = X_audio_val\n",
    "    elif input_type == \"both\":\n",
    "        X_train = tf.concat([X_rgb_train, X_audio_train],1)\n",
    "        X_val = tf.concat([X_rgb_val, X_audio_val],1)\n",
    "    else:\n",
    "        print(\"invalid input type\")\n",
    "        raise ValueError\n",
    "    return X_train,X_val,y_train,y_val\n",
    "\n",
    "def build_logistic(l2= 1e-8):\n",
    "    logistic_reg = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(n_labels, activation='sigmoid',\n",
    "        kernel_regularizer=tf.keras.regularizers.L2(l2))])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD()\n",
    "    logistic_reg.compile(optimizer,\n",
    "                loss=tf.keras.losses.BinaryCrossentropy())\n",
    "    return logistic_reg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With just rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/800\n",
      "11/11 [==============================] - 1s 31ms/step - loss: 6.0358 - val_loss: 0.3263\n",
      "Epoch 2/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.3146 - val_loss: 0.2967\n",
      "Epoch 3/800\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.2946 - val_loss: 0.2861\n",
      "Epoch 4/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2847 - val_loss: 0.2787\n",
      "Epoch 5/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2790 - val_loss: 0.2750\n",
      "Epoch 6/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2749 - val_loss: 0.2735\n",
      "Epoch 7/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2719 - val_loss: 0.2732\n",
      "Epoch 8/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2701 - val_loss: 0.2685\n",
      "Epoch 9/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2675 - val_loss: 0.2672\n",
      "Epoch 10/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.2658 - val_loss: 0.2670\n",
      "Epoch 11/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2640 - val_loss: 0.2650\n",
      "Epoch 12/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2625 - val_loss: 0.2630\n",
      "Epoch 13/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2612 - val_loss: 0.2611\n",
      "Epoch 14/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2598 - val_loss: 0.2618\n",
      "Epoch 15/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2589 - val_loss: 0.2622\n",
      "Epoch 16/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2578 - val_loss: 0.2592\n",
      "Epoch 17/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2566 - val_loss: 0.2582\n",
      "Epoch 18/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2557 - val_loss: 0.2576\n",
      "Epoch 19/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2548 - val_loss: 0.2572\n",
      "Epoch 20/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2539 - val_loss: 0.2561\n",
      "Epoch 21/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2530 - val_loss: 0.2561\n",
      "Epoch 22/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2526 - val_loss: 0.2552\n",
      "Epoch 23/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2516 - val_loss: 0.2552\n",
      "Epoch 24/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2511 - val_loss: 0.2568\n",
      "Epoch 25/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2503 - val_loss: 0.2545\n",
      "Epoch 26/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2493 - val_loss: 0.2558\n",
      "Epoch 27/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2488 - val_loss: 0.2528\n",
      "Epoch 28/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2480 - val_loss: 0.2528\n",
      "Epoch 29/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2475 - val_loss: 0.2532\n",
      "Epoch 30/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2467 - val_loss: 0.2528\n",
      "Epoch 31/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2465 - val_loss: 0.2519\n",
      "Epoch 32/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2454 - val_loss: 0.2517\n",
      "Epoch 33/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2447 - val_loss: 0.2516\n",
      "Epoch 34/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2443 - val_loss: 0.2503\n",
      "Epoch 35/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2435 - val_loss: 0.2494\n",
      "Epoch 36/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2432 - val_loss: 0.2495\n",
      "Epoch 37/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2422 - val_loss: 0.2488\n",
      "Epoch 38/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2416 - val_loss: 0.2510\n",
      "Epoch 39/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2414 - val_loss: 0.2497\n",
      "Epoch 40/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2410 - val_loss: 0.2478\n",
      "Epoch 41/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2403 - val_loss: 0.2472\n",
      "Epoch 42/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2397 - val_loss: 0.2487\n",
      "Epoch 43/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2394 - val_loss: 0.2482\n",
      "Epoch 44/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2386 - val_loss: 0.2461\n",
      "Epoch 45/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2378 - val_loss: 0.2462\n",
      "Epoch 46/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2374 - val_loss: 0.2480\n",
      "Epoch 47/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2372 - val_loss: 0.2462\n",
      "Epoch 48/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2363 - val_loss: 0.2454\n",
      "Epoch 49/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2360 - val_loss: 0.2452\n",
      "Epoch 50/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2352 - val_loss: 0.2453\n",
      "Epoch 51/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2350 - val_loss: 0.2442\n",
      "Epoch 52/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2345 - val_loss: 0.2439\n",
      "Epoch 53/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2339 - val_loss: 0.2438\n",
      "Epoch 54/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2334 - val_loss: 0.2437\n",
      "Epoch 55/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2327 - val_loss: 0.2431\n",
      "Epoch 56/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2322 - val_loss: 0.2440\n",
      "Epoch 57/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2318 - val_loss: 0.2429\n",
      "Epoch 58/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2315 - val_loss: 0.2430\n",
      "Epoch 59/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2311 - val_loss: 0.2422\n",
      "Epoch 60/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2304 - val_loss: 0.2427\n",
      "Epoch 61/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2301 - val_loss: 0.2411\n",
      "Epoch 62/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2295 - val_loss: 0.2441\n",
      "Epoch 63/800\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 0.2291 - val_loss: 0.2418\n",
      "Epoch 64/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.2288 - val_loss: 0.2420\n",
      "Epoch 65/800\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.2280 - val_loss: 0.2410\n",
      "Epoch 66/800\n",
      "11/11 [==============================] - 1s 59ms/step - loss: 0.2277 - val_loss: 0.2409\n",
      "Epoch 67/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.2274 - val_loss: 0.2407\n",
      "Epoch 68/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.2268 - val_loss: 0.2414\n",
      "Epoch 69/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2264 - val_loss: 0.2392\n",
      "Epoch 70/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2258 - val_loss: 0.2388\n",
      "Epoch 71/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2251 - val_loss: 0.2386\n",
      "Epoch 72/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2249 - val_loss: 0.2379\n",
      "Epoch 73/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2244 - val_loss: 0.2375\n",
      "Epoch 74/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2238 - val_loss: 0.2402\n",
      "Epoch 75/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2239 - val_loss: 0.2366\n",
      "Epoch 76/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2229 - val_loss: 0.2402\n",
      "Epoch 77/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2228 - val_loss: 0.2387\n",
      "Epoch 78/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2223 - val_loss: 0.2361\n",
      "Epoch 79/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2215 - val_loss: 0.2365\n",
      "Epoch 80/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2217 - val_loss: 0.2356\n",
      "Epoch 81/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2209 - val_loss: 0.2361\n",
      "Epoch 82/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2205 - val_loss: 0.2352\n",
      "Epoch 83/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2197 - val_loss: 0.2360\n",
      "Epoch 84/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2195 - val_loss: 0.2352\n",
      "Epoch 85/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2192 - val_loss: 0.2373\n",
      "Epoch 86/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2191 - val_loss: 0.2343\n",
      "Epoch 87/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2181 - val_loss: 0.2345\n",
      "Epoch 88/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2181 - val_loss: 0.2339\n",
      "Epoch 89/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2171 - val_loss: 0.2343\n",
      "Epoch 90/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2170 - val_loss: 0.2336\n",
      "Epoch 91/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2164 - val_loss: 0.2337\n",
      "Epoch 92/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2166 - val_loss: 0.2326\n",
      "Epoch 93/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2156 - val_loss: 0.2327\n",
      "Epoch 94/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2154 - val_loss: 0.2323\n",
      "Epoch 95/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2153 - val_loss: 0.2326\n",
      "Epoch 96/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2146 - val_loss: 0.2320\n",
      "Epoch 97/800\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.2142 - val_loss: 0.2317\n",
      "Epoch 98/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2137 - val_loss: 0.2353\n",
      "Epoch 99/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2136 - val_loss: 0.2316\n",
      "Epoch 100/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2130 - val_loss: 0.2318\n",
      "Epoch 101/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2125 - val_loss: 0.2307\n",
      "Epoch 102/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2122 - val_loss: 0.2304\n",
      "Epoch 103/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2115 - val_loss: 0.2308\n",
      "Epoch 104/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2113 - val_loss: 0.2301\n",
      "Epoch 105/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2108 - val_loss: 0.2314\n",
      "Epoch 106/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2105 - val_loss: 0.2310\n",
      "Epoch 107/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2102 - val_loss: 0.2300\n",
      "Epoch 108/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2097 - val_loss: 0.2301\n",
      "Epoch 109/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2094 - val_loss: 0.2304\n",
      "Epoch 110/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2091 - val_loss: 0.2302\n",
      "Epoch 111/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2089 - val_loss: 0.2288\n",
      "Epoch 112/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2081 - val_loss: 0.2329\n",
      "Epoch 113/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2085 - val_loss: 0.2281\n",
      "Epoch 114/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2074 - val_loss: 0.2279\n",
      "Epoch 115/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2069 - val_loss: 0.2274\n",
      "Epoch 116/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2064 - val_loss: 0.2274\n",
      "Epoch 117/800\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.2062 - val_loss: 0.2268\n",
      "Epoch 118/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2060 - val_loss: 0.2266\n",
      "Epoch 119/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2054 - val_loss: 0.2268\n",
      "Epoch 120/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2053 - val_loss: 0.2261\n",
      "Epoch 121/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2047 - val_loss: 0.2269\n",
      "Epoch 122/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2043 - val_loss: 0.2283\n",
      "Epoch 123/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.2048 - val_loss: 0.2268\n",
      "Epoch 124/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2039 - val_loss: 0.2257\n",
      "Epoch 125/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2034 - val_loss: 0.2255\n",
      "Epoch 126/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2029 - val_loss: 0.2267\n",
      "Epoch 127/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2026 - val_loss: 0.2250\n",
      "Epoch 128/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2020 - val_loss: 0.2250\n",
      "Epoch 129/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2018 - val_loss: 0.2256\n",
      "Epoch 130/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2018 - val_loss: 0.2249\n",
      "Epoch 131/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.2012 - val_loss: 0.2237\n",
      "Epoch 132/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2006 - val_loss: 0.2242\n",
      "Epoch 133/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.2004 - val_loss: 0.2233\n",
      "Epoch 134/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1998 - val_loss: 0.2233\n",
      "Epoch 135/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1997 - val_loss: 0.2257\n",
      "Epoch 136/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.2000 - val_loss: 0.2235\n",
      "Epoch 137/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1991 - val_loss: 0.2231\n",
      "Epoch 138/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1987 - val_loss: 0.2233\n",
      "Epoch 139/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1983 - val_loss: 0.2227\n",
      "Epoch 140/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1981 - val_loss: 0.2220\n",
      "Epoch 141/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1973 - val_loss: 0.2224\n",
      "Epoch 142/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1973 - val_loss: 0.2217\n",
      "Epoch 143/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1972 - val_loss: 0.2282\n",
      "Epoch 144/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1976 - val_loss: 0.2251\n",
      "Epoch 145/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1967 - val_loss: 0.2213\n",
      "Epoch 146/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1957 - val_loss: 0.2227\n",
      "Epoch 147/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1956 - val_loss: 0.2203\n",
      "Epoch 148/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1949 - val_loss: 0.2200\n",
      "Epoch 149/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1946 - val_loss: 0.2210\n",
      "Epoch 150/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1943 - val_loss: 0.2217\n",
      "Epoch 151/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1941 - val_loss: 0.2197\n",
      "Epoch 152/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1936 - val_loss: 0.2212\n",
      "Epoch 153/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1933 - val_loss: 0.2196\n",
      "Epoch 154/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1929 - val_loss: 0.2218\n",
      "Epoch 155/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1932 - val_loss: 0.2192\n",
      "Epoch 156/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1923 - val_loss: 0.2214\n",
      "Epoch 157/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1921 - val_loss: 0.2210\n",
      "Epoch 158/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1920 - val_loss: 0.2216\n",
      "Epoch 159/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1916 - val_loss: 0.2188\n",
      "Epoch 160/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1910 - val_loss: 0.2180\n",
      "Epoch 161/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1906 - val_loss: 0.2179\n",
      "Epoch 162/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1903 - val_loss: 0.2187\n",
      "Epoch 163/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1900 - val_loss: 0.2186\n",
      "Epoch 164/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1898 - val_loss: 0.2220\n",
      "Epoch 165/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1899 - val_loss: 0.2177\n",
      "Epoch 166/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1892 - val_loss: 0.2170\n",
      "Epoch 167/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1887 - val_loss: 0.2179\n",
      "Epoch 168/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1886 - val_loss: 0.2171\n",
      "Epoch 169/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1882 - val_loss: 0.2172\n",
      "Epoch 170/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1879 - val_loss: 0.2191\n",
      "Epoch 171/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1876 - val_loss: 0.2186\n",
      "Epoch 172/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1875 - val_loss: 0.2166\n",
      "Epoch 173/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1870 - val_loss: 0.2178\n",
      "Epoch 174/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1868 - val_loss: 0.2168\n",
      "Epoch 175/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1864 - val_loss: 0.2159\n",
      "Epoch 176/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1860 - val_loss: 0.2154\n",
      "Epoch 177/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1856 - val_loss: 0.2156\n",
      "Epoch 178/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1853 - val_loss: 0.2156\n",
      "Epoch 179/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1852 - val_loss: 0.2153\n",
      "Epoch 180/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1846 - val_loss: 0.2163\n",
      "Epoch 181/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1843 - val_loss: 0.2146\n",
      "Epoch 182/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1842 - val_loss: 0.2162\n",
      "Epoch 183/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1839 - val_loss: 0.2155\n",
      "Epoch 184/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1837 - val_loss: 0.2145\n",
      "Epoch 185/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1831 - val_loss: 0.2163\n",
      "Epoch 186/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1832 - val_loss: 0.2145\n",
      "Epoch 187/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1827 - val_loss: 0.2169\n",
      "Epoch 188/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1828 - val_loss: 0.2148\n",
      "Epoch 189/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1822 - val_loss: 0.2138\n",
      "Epoch 190/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1818 - val_loss: 0.2143\n",
      "Epoch 191/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1817 - val_loss: 0.2135\n",
      "Epoch 192/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1810 - val_loss: 0.2129\n",
      "Epoch 193/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1810 - val_loss: 0.2132\n",
      "Epoch 194/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1806 - val_loss: 0.2131\n",
      "Epoch 195/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1803 - val_loss: 0.2120\n",
      "Epoch 196/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1801 - val_loss: 0.2131\n",
      "Epoch 197/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1798 - val_loss: 0.2116\n",
      "Epoch 198/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1796 - val_loss: 0.2118\n",
      "Epoch 199/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1791 - val_loss: 0.2125\n",
      "Epoch 200/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1789 - val_loss: 0.2134\n",
      "Epoch 201/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1788 - val_loss: 0.2118\n",
      "Epoch 202/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1784 - val_loss: 0.2129\n",
      "Epoch 203/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1782 - val_loss: 0.2115\n",
      "Epoch 204/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1777 - val_loss: 0.2120\n",
      "Epoch 205/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1776 - val_loss: 0.2112\n",
      "Epoch 206/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1773 - val_loss: 0.2118\n",
      "Epoch 207/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1771 - val_loss: 0.2133\n",
      "Epoch 208/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1768 - val_loss: 0.2108\n",
      "Epoch 209/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1763 - val_loss: 0.2113\n",
      "Epoch 210/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1760 - val_loss: 0.2115\n",
      "Epoch 211/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1760 - val_loss: 0.2101\n",
      "Epoch 212/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1756 - val_loss: 0.2106\n",
      "Epoch 213/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1752 - val_loss: 0.2095\n",
      "Epoch 214/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1749 - val_loss: 0.2102\n",
      "Epoch 215/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1746 - val_loss: 0.2092\n",
      "Epoch 216/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1745 - val_loss: 0.2093\n",
      "Epoch 217/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1743 - val_loss: 0.2089\n",
      "Epoch 218/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1740 - val_loss: 0.2099\n",
      "Epoch 219/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1738 - val_loss: 0.2094\n",
      "Epoch 220/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1734 - val_loss: 0.2097\n",
      "Epoch 221/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1732 - val_loss: 0.2093\n",
      "Epoch 222/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1729 - val_loss: 0.2079\n",
      "Epoch 223/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1727 - val_loss: 0.2088\n",
      "Epoch 224/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1722 - val_loss: 0.2085\n",
      "Epoch 225/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1720 - val_loss: 0.2086\n",
      "Epoch 226/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1718 - val_loss: 0.2090\n",
      "Epoch 227/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1716 - val_loss: 0.2085\n",
      "Epoch 228/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1713 - val_loss: 0.2083\n",
      "Epoch 229/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1711 - val_loss: 0.2089\n",
      "Epoch 230/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1711 - val_loss: 0.2085\n",
      "Epoch 231/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1711 - val_loss: 0.2081\n",
      "Epoch 232/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1702 - val_loss: 0.2092\n",
      "Epoch 233/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1700 - val_loss: 0.2079\n",
      "Epoch 234/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1699 - val_loss: 0.2070\n",
      "Epoch 235/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.1695 - val_loss: 0.2080\n",
      "Epoch 236/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1695 - val_loss: 0.2085\n",
      "Epoch 237/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1693 - val_loss: 0.2073\n",
      "Epoch 238/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1690 - val_loss: 0.2056\n",
      "Epoch 239/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1684 - val_loss: 0.2064\n",
      "Epoch 240/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1685 - val_loss: 0.2087\n",
      "Epoch 241/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1683 - val_loss: 0.2065\n",
      "Epoch 242/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1677 - val_loss: 0.2057\n",
      "Epoch 243/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1674 - val_loss: 0.2060\n",
      "Epoch 244/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1673 - val_loss: 0.2054\n",
      "Epoch 245/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1670 - val_loss: 0.2083\n",
      "Epoch 246/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1672 - val_loss: 0.2052\n",
      "Epoch 247/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1664 - val_loss: 0.2067\n",
      "Epoch 248/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1663 - val_loss: 0.2061\n",
      "Epoch 249/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1661 - val_loss: 0.2081\n",
      "Epoch 250/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1661 - val_loss: 0.2056\n",
      "Epoch 251/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1655 - val_loss: 0.2052\n",
      "Epoch 252/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1653 - val_loss: 0.2045\n",
      "Epoch 253/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1652 - val_loss: 0.2053\n",
      "Epoch 254/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1647 - val_loss: 0.2045\n",
      "Epoch 255/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1646 - val_loss: 0.2065\n",
      "Epoch 256/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1646 - val_loss: 0.2054\n",
      "Epoch 257/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1640 - val_loss: 0.2039\n",
      "Epoch 258/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1637 - val_loss: 0.2039\n",
      "Epoch 259/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1635 - val_loss: 0.2042\n",
      "Epoch 260/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1633 - val_loss: 0.2050\n",
      "Epoch 261/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1635 - val_loss: 0.2046\n",
      "Epoch 262/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1632 - val_loss: 0.2041\n",
      "Epoch 263/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1626 - val_loss: 0.2047\n",
      "Epoch 264/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1625 - val_loss: 0.2031\n",
      "Epoch 265/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1623 - val_loss: 0.2027\n",
      "Epoch 266/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1619 - val_loss: 0.2039\n",
      "Epoch 267/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1619 - val_loss: 0.2046\n",
      "Epoch 268/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1616 - val_loss: 0.2025\n",
      "Epoch 269/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1613 - val_loss: 0.2036\n",
      "Epoch 270/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1611 - val_loss: 0.2048\n",
      "Epoch 271/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1611 - val_loss: 0.2028\n",
      "Epoch 272/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1606 - val_loss: 0.2024\n",
      "Epoch 273/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1605 - val_loss: 0.2024\n",
      "Epoch 274/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1603 - val_loss: 0.2028\n",
      "Epoch 275/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1600 - val_loss: 0.2025\n",
      "Epoch 276/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1598 - val_loss: 0.2021\n",
      "Epoch 277/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1596 - val_loss: 0.2038\n",
      "Epoch 278/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1597 - val_loss: 0.2029\n",
      "Epoch 279/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1592 - val_loss: 0.2034\n",
      "Epoch 280/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1590 - val_loss: 0.2017\n",
      "Epoch 281/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1588 - val_loss: 0.2019\n",
      "Epoch 282/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1585 - val_loss: 0.2019\n",
      "Epoch 283/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1582 - val_loss: 0.2012\n",
      "Epoch 284/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1580 - val_loss: 0.2018\n",
      "Epoch 285/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1578 - val_loss: 0.2032\n",
      "Epoch 286/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1578 - val_loss: 0.2009\n",
      "Epoch 287/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1573 - val_loss: 0.2009\n",
      "Epoch 288/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1571 - val_loss: 0.2012\n",
      "Epoch 289/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1569 - val_loss: 0.2009\n",
      "Epoch 290/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1566 - val_loss: 0.2014\n",
      "Epoch 291/800\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.1565 - val_loss: 0.2010\n",
      "Epoch 292/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1562 - val_loss: 0.2007\n",
      "Epoch 293/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1560 - val_loss: 0.2000\n",
      "Epoch 294/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1559 - val_loss: 0.1998\n",
      "Epoch 295/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1556 - val_loss: 0.2010\n",
      "Epoch 296/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1555 - val_loss: 0.2010\n",
      "Epoch 297/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1553 - val_loss: 0.1996\n",
      "Epoch 298/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1549 - val_loss: 0.2000\n",
      "Epoch 299/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1547 - val_loss: 0.1990\n",
      "Epoch 300/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1545 - val_loss: 0.1994\n",
      "Epoch 301/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1542 - val_loss: 0.1992\n",
      "Epoch 302/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1542 - val_loss: 0.2009\n",
      "Epoch 303/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1539 - val_loss: 0.1999\n",
      "Epoch 304/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1539 - val_loss: 0.1989\n",
      "Epoch 305/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1534 - val_loss: 0.1989\n",
      "Epoch 306/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1532 - val_loss: 0.1994\n",
      "Epoch 307/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1531 - val_loss: 0.1989\n",
      "Epoch 308/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1529 - val_loss: 0.1992\n",
      "Epoch 309/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1527 - val_loss: 0.2004\n",
      "Epoch 310/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1526 - val_loss: 0.1984\n",
      "Epoch 311/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1523 - val_loss: 0.1983\n",
      "Epoch 312/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1521 - val_loss: 0.2002\n",
      "Epoch 313/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1522 - val_loss: 0.2020\n",
      "Epoch 314/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1522 - val_loss: 0.1989\n",
      "Epoch 315/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1516 - val_loss: 0.1994\n",
      "Epoch 316/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1513 - val_loss: 0.1986\n",
      "Epoch 317/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1510 - val_loss: 0.2003\n",
      "Epoch 318/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1511 - val_loss: 0.1984\n",
      "Epoch 319/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1506 - val_loss: 0.1973\n",
      "Epoch 320/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1504 - val_loss: 0.1986\n",
      "Epoch 321/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1505 - val_loss: 0.1980\n",
      "Epoch 322/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1501 - val_loss: 0.1987\n",
      "Epoch 323/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1501 - val_loss: 0.1974\n",
      "Epoch 324/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1498 - val_loss: 0.1977\n",
      "Epoch 325/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1494 - val_loss: 0.1971\n",
      "Epoch 326/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1493 - val_loss: 0.1978\n",
      "Epoch 327/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1492 - val_loss: 0.1976\n",
      "Epoch 328/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1491 - val_loss: 0.1975\n",
      "Epoch 329/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1488 - val_loss: 0.1971\n",
      "Epoch 330/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1485 - val_loss: 0.1985\n",
      "Epoch 331/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1484 - val_loss: 0.1970\n",
      "Epoch 332/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1482 - val_loss: 0.1984\n",
      "Epoch 333/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1484 - val_loss: 0.1963\n",
      "Epoch 334/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1477 - val_loss: 0.1973\n",
      "Epoch 335/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1476 - val_loss: 0.1959\n",
      "Epoch 336/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1472 - val_loss: 0.1972\n",
      "Epoch 337/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1473 - val_loss: 0.1973\n",
      "Epoch 338/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1472 - val_loss: 0.1963\n",
      "Epoch 339/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1470 - val_loss: 0.1971\n",
      "Epoch 340/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1467 - val_loss: 0.1971\n",
      "Epoch 341/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1465 - val_loss: 0.1963\n",
      "Epoch 342/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1463 - val_loss: 0.1954\n",
      "Epoch 343/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1460 - val_loss: 0.1964\n",
      "Epoch 344/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1459 - val_loss: 0.1967\n",
      "Epoch 345/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1457 - val_loss: 0.1958\n",
      "Epoch 346/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1456 - val_loss: 0.1957\n",
      "Epoch 347/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1454 - val_loss: 0.1954\n",
      "Epoch 348/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1451 - val_loss: 0.1962\n",
      "Epoch 349/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1451 - val_loss: 0.1953\n",
      "Epoch 350/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1448 - val_loss: 0.1954\n",
      "Epoch 351/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1446 - val_loss: 0.1954\n",
      "Epoch 352/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1443 - val_loss: 0.1948\n",
      "Epoch 353/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1443 - val_loss: 0.1955\n",
      "Epoch 354/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1441 - val_loss: 0.1944\n",
      "Epoch 355/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1439 - val_loss: 0.1944\n",
      "Epoch 356/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1438 - val_loss: 0.1948\n",
      "Epoch 357/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1435 - val_loss: 0.1951\n",
      "Epoch 358/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1433 - val_loss: 0.1948\n",
      "Epoch 359/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1432 - val_loss: 0.1957\n",
      "Epoch 360/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1430 - val_loss: 0.1945\n",
      "Epoch 361/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1428 - val_loss: 0.1954\n",
      "Epoch 362/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1427 - val_loss: 0.1941\n",
      "Epoch 363/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1425 - val_loss: 0.1951\n",
      "Epoch 364/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1423 - val_loss: 0.1951\n",
      "Epoch 365/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1421 - val_loss: 0.1938\n",
      "Epoch 366/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1418 - val_loss: 0.1938\n",
      "Epoch 367/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1416 - val_loss: 0.1950\n",
      "Epoch 368/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1415 - val_loss: 0.1940\n",
      "Epoch 369/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1413 - val_loss: 0.1937\n",
      "Epoch 370/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1411 - val_loss: 0.1936\n",
      "Epoch 371/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1409 - val_loss: 0.1934\n",
      "Epoch 372/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1408 - val_loss: 0.1946\n",
      "Epoch 373/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1409 - val_loss: 0.1943\n",
      "Epoch 374/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1405 - val_loss: 0.1936\n",
      "Epoch 375/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1403 - val_loss: 0.1945\n",
      "Epoch 376/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1402 - val_loss: 0.1937\n",
      "Epoch 377/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1400 - val_loss: 0.1934\n",
      "Epoch 378/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1397 - val_loss: 0.1939\n",
      "Epoch 379/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1395 - val_loss: 0.1946\n",
      "Epoch 380/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1395 - val_loss: 0.1932\n",
      "Epoch 381/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1392 - val_loss: 0.1926\n",
      "Epoch 382/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1391 - val_loss: 0.1945\n",
      "Epoch 383/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1391 - val_loss: 0.1923\n",
      "Epoch 384/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1387 - val_loss: 0.1935\n",
      "Epoch 385/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1386 - val_loss: 0.1930\n",
      "Epoch 386/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1384 - val_loss: 0.1932\n",
      "Epoch 387/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1382 - val_loss: 0.1933\n",
      "Epoch 388/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1381 - val_loss: 0.1930\n",
      "Epoch 389/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1379 - val_loss: 0.1924\n",
      "Epoch 390/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1378 - val_loss: 0.1926\n",
      "Epoch 391/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1376 - val_loss: 0.1924\n",
      "Epoch 392/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1375 - val_loss: 0.1946\n",
      "Epoch 393/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1375 - val_loss: 0.1923\n",
      "Epoch 394/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1370 - val_loss: 0.1919\n",
      "Epoch 395/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1369 - val_loss: 0.1924\n",
      "Epoch 396/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1368 - val_loss: 0.1932\n",
      "Epoch 397/800\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.1365 - val_loss: 0.1919\n",
      "Epoch 398/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1363 - val_loss: 0.1926\n",
      "Epoch 399/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1363 - val_loss: 0.1923\n",
      "Epoch 400/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1362 - val_loss: 0.1922\n",
      "Epoch 401/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1359 - val_loss: 0.1917\n",
      "Epoch 402/800\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.1358 - val_loss: 0.1923\n",
      "Epoch 403/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1357 - val_loss: 0.1927\n",
      "Epoch 404/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1356 - val_loss: 0.1920\n",
      "Epoch 405/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1352 - val_loss: 0.1909\n",
      "Epoch 406/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1352 - val_loss: 0.1914\n",
      "Epoch 407/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1350 - val_loss: 0.1911\n",
      "Epoch 408/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1348 - val_loss: 0.1914\n",
      "Epoch 409/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1346 - val_loss: 0.1915\n",
      "Epoch 410/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1344 - val_loss: 0.1913\n",
      "Epoch 411/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1344 - val_loss: 0.1909\n",
      "Epoch 412/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1341 - val_loss: 0.1911\n",
      "Epoch 413/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1340 - val_loss: 0.1913\n",
      "Epoch 414/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1339 - val_loss: 0.1922\n",
      "Epoch 415/800\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.1338 - val_loss: 0.1909\n",
      "Epoch 416/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1335 - val_loss: 0.1927\n",
      "Epoch 417/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1335 - val_loss: 0.1912\n",
      "Epoch 418/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1333 - val_loss: 0.1919\n",
      "Epoch 419/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1331 - val_loss: 0.1902\n",
      "Epoch 420/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1329 - val_loss: 0.1908\n",
      "Epoch 421/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1328 - val_loss: 0.1908\n",
      "Epoch 422/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1326 - val_loss: 0.1906\n",
      "Epoch 423/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1325 - val_loss: 0.1914\n",
      "Epoch 424/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1323 - val_loss: 0.1907\n",
      "Epoch 425/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1321 - val_loss: 0.1899\n",
      "Epoch 426/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1319 - val_loss: 0.1904\n",
      "Epoch 427/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1319 - val_loss: 0.1909\n",
      "Epoch 428/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1317 - val_loss: 0.1905\n",
      "Epoch 429/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1315 - val_loss: 0.1911\n",
      "Epoch 430/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1315 - val_loss: 0.1897\n",
      "Epoch 431/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1311 - val_loss: 0.1896\n",
      "Epoch 432/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1310 - val_loss: 0.1896\n",
      "Epoch 433/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1310 - val_loss: 0.1909\n",
      "Epoch 434/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1311 - val_loss: 0.1899\n",
      "Epoch 435/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1306 - val_loss: 0.1895\n",
      "Epoch 436/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1304 - val_loss: 0.1907\n",
      "Epoch 437/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1303 - val_loss: 0.1892\n",
      "Epoch 438/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1301 - val_loss: 0.1898\n",
      "Epoch 439/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1299 - val_loss: 0.1923\n",
      "Epoch 440/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1301 - val_loss: 0.1896\n",
      "Epoch 441/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1297 - val_loss: 0.1890\n",
      "Epoch 442/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1295 - val_loss: 0.1895\n",
      "Epoch 443/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1292 - val_loss: 0.1891\n",
      "Epoch 444/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1292 - val_loss: 0.1897\n",
      "Epoch 445/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1291 - val_loss: 0.1893\n",
      "Epoch 446/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1289 - val_loss: 0.1893\n",
      "Epoch 447/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1288 - val_loss: 0.1882\n",
      "Epoch 448/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1286 - val_loss: 0.1902\n",
      "Epoch 449/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1285 - val_loss: 0.1892\n",
      "Epoch 450/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1283 - val_loss: 0.1892\n",
      "Epoch 451/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1283 - val_loss: 0.1887\n",
      "Epoch 452/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1280 - val_loss: 0.1888\n",
      "Epoch 453/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1279 - val_loss: 0.1888\n",
      "Epoch 454/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1277 - val_loss: 0.1894\n",
      "Epoch 455/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1276 - val_loss: 0.1885\n",
      "Epoch 456/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1275 - val_loss: 0.1888\n",
      "Epoch 457/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1273 - val_loss: 0.1881\n",
      "Epoch 458/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1272 - val_loss: 0.1886\n",
      "Epoch 459/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1270 - val_loss: 0.1898\n",
      "Epoch 460/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1270 - val_loss: 0.1881\n",
      "Epoch 461/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1267 - val_loss: 0.1883\n",
      "Epoch 462/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1265 - val_loss: 0.1877\n",
      "Epoch 463/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1266 - val_loss: 0.1874\n",
      "Epoch 464/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1263 - val_loss: 0.1888\n",
      "Epoch 465/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1262 - val_loss: 0.1887\n",
      "Epoch 466/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1260 - val_loss: 0.1881\n",
      "Epoch 467/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1258 - val_loss: 0.1882\n",
      "Epoch 468/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1257 - val_loss: 0.1883\n",
      "Epoch 469/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1256 - val_loss: 0.1903\n",
      "Epoch 470/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1259 - val_loss: 0.1883\n",
      "Epoch 471/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1254 - val_loss: 0.1878\n",
      "Epoch 472/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1251 - val_loss: 0.1874\n",
      "Epoch 473/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1250 - val_loss: 0.1872\n",
      "Epoch 474/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1248 - val_loss: 0.1882\n",
      "Epoch 475/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1247 - val_loss: 0.1886\n",
      "Epoch 476/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1246 - val_loss: 0.1876\n",
      "Epoch 477/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1245 - val_loss: 0.1885\n",
      "Epoch 478/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1243 - val_loss: 0.1877\n",
      "Epoch 479/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1242 - val_loss: 0.1879\n",
      "Epoch 480/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1242 - val_loss: 0.1879\n",
      "Epoch 481/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1240 - val_loss: 0.1885\n",
      "Epoch 482/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1238 - val_loss: 0.1877\n",
      "Epoch 483/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1237 - val_loss: 0.1878\n",
      "Epoch 484/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1235 - val_loss: 0.1875\n",
      "Epoch 485/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1233 - val_loss: 0.1875\n",
      "Epoch 486/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1232 - val_loss: 0.1874\n",
      "Epoch 487/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1231 - val_loss: 0.1865\n",
      "Epoch 488/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1229 - val_loss: 0.1862\n",
      "Epoch 489/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1228 - val_loss: 0.1864\n",
      "Epoch 490/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1226 - val_loss: 0.1870\n",
      "Epoch 491/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1225 - val_loss: 0.1861\n",
      "Epoch 492/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1224 - val_loss: 0.1868\n",
      "Epoch 493/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1222 - val_loss: 0.1874\n",
      "Epoch 494/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1224 - val_loss: 0.1880\n",
      "Epoch 495/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1221 - val_loss: 0.1871\n",
      "Epoch 496/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1220 - val_loss: 0.1865\n",
      "Epoch 497/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1217 - val_loss: 0.1872\n",
      "Epoch 498/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1218 - val_loss: 0.1870\n",
      "Epoch 499/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1215 - val_loss: 0.1874\n",
      "Epoch 500/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1214 - val_loss: 0.1871\n",
      "Epoch 501/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1211 - val_loss: 0.1860\n",
      "Epoch 502/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1211 - val_loss: 0.1861\n",
      "Epoch 503/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1209 - val_loss: 0.1874\n",
      "Epoch 504/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1208 - val_loss: 0.1860\n",
      "Epoch 505/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1208 - val_loss: 0.1860\n",
      "Epoch 506/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1206 - val_loss: 0.1870\n",
      "Epoch 507/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1206 - val_loss: 0.1870\n",
      "Epoch 508/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1204 - val_loss: 0.1867\n",
      "Epoch 509/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1202 - val_loss: 0.1868\n",
      "Epoch 510/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1203 - val_loss: 0.1873\n",
      "Epoch 511/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1199 - val_loss: 0.1865\n",
      "Epoch 512/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1198 - val_loss: 0.1861\n",
      "Epoch 513/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1197 - val_loss: 0.1875\n",
      "Epoch 514/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1196 - val_loss: 0.1862\n",
      "Epoch 515/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1194 - val_loss: 0.1849\n",
      "Epoch 516/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1193 - val_loss: 0.1852\n",
      "Epoch 517/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1192 - val_loss: 0.1852\n",
      "Epoch 518/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1191 - val_loss: 0.1861\n",
      "Epoch 519/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1189 - val_loss: 0.1857\n",
      "Epoch 520/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1188 - val_loss: 0.1852\n",
      "Epoch 521/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1186 - val_loss: 0.1858\n",
      "Epoch 522/800\n",
      "11/11 [==============================] - 1s 99ms/step - loss: 0.1185 - val_loss: 0.1860\n",
      "Epoch 523/800\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.1184 - val_loss: 0.1857\n",
      "Epoch 524/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1182 - val_loss: 0.1851\n",
      "Epoch 525/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1181 - val_loss: 0.1853\n",
      "Epoch 526/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1180 - val_loss: 0.1851\n",
      "Epoch 527/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1178 - val_loss: 0.1856\n",
      "Epoch 528/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1177 - val_loss: 0.1862\n",
      "Epoch 529/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1176 - val_loss: 0.1859\n",
      "Epoch 530/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1175 - val_loss: 0.1850\n",
      "Epoch 531/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1173 - val_loss: 0.1857\n",
      "Epoch 532/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1173 - val_loss: 0.1852\n",
      "Epoch 533/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1171 - val_loss: 0.1846\n",
      "Epoch 534/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1170 - val_loss: 0.1850\n",
      "Epoch 535/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1169 - val_loss: 0.1859\n",
      "Epoch 536/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1168 - val_loss: 0.1858\n",
      "Epoch 537/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1168 - val_loss: 0.1856\n",
      "Epoch 538/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1165 - val_loss: 0.1851\n",
      "Epoch 539/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1164 - val_loss: 0.1855\n",
      "Epoch 540/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1164 - val_loss: 0.1846\n",
      "Epoch 541/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1162 - val_loss: 0.1850\n",
      "Epoch 542/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1160 - val_loss: 0.1850\n",
      "Epoch 543/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1158 - val_loss: 0.1849\n",
      "Epoch 544/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1158 - val_loss: 0.1845\n",
      "Epoch 545/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1156 - val_loss: 0.1854\n",
      "Epoch 546/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1156 - val_loss: 0.1858\n",
      "Epoch 547/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1155 - val_loss: 0.1841\n",
      "Epoch 548/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1152 - val_loss: 0.1847\n",
      "Epoch 549/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1152 - val_loss: 0.1846\n",
      "Epoch 550/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1150 - val_loss: 0.1846\n",
      "Epoch 551/800\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.1149 - val_loss: 0.1844\n",
      "Epoch 552/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1148 - val_loss: 0.1855\n",
      "Epoch 553/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1148 - val_loss: 0.1855\n",
      "Epoch 554/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1147 - val_loss: 0.1846\n",
      "Epoch 555/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1145 - val_loss: 0.1841\n",
      "Epoch 556/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1144 - val_loss: 0.1845\n",
      "Epoch 557/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1142 - val_loss: 0.1841\n",
      "Epoch 558/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1142 - val_loss: 0.1843\n",
      "Epoch 559/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1139 - val_loss: 0.1849\n",
      "Epoch 560/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1139 - val_loss: 0.1853\n",
      "Epoch 561/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1138 - val_loss: 0.1840\n",
      "Epoch 562/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1137 - val_loss: 0.1843\n",
      "Epoch 563/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1134 - val_loss: 0.1839\n",
      "Epoch 564/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1134 - val_loss: 0.1839\n",
      "Epoch 565/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1133 - val_loss: 0.1844\n",
      "Epoch 566/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1131 - val_loss: 0.1845\n",
      "Epoch 567/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.1130 - val_loss: 0.1842\n",
      "Epoch 568/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1130 - val_loss: 0.1841\n",
      "Epoch 569/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1128 - val_loss: 0.1842\n",
      "Epoch 570/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1127 - val_loss: 0.1841\n",
      "Epoch 571/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1126 - val_loss: 0.1842\n",
      "Epoch 572/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1124 - val_loss: 0.1838\n",
      "Epoch 573/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1123 - val_loss: 0.1856\n",
      "Epoch 574/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1123 - val_loss: 0.1837\n",
      "Epoch 575/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1122 - val_loss: 0.1832\n",
      "Epoch 576/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1119 - val_loss: 0.1841\n",
      "Epoch 577/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1120 - val_loss: 0.1843\n",
      "Epoch 578/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1119 - val_loss: 0.1848\n",
      "Epoch 579/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.1118 - val_loss: 0.1844\n",
      "Epoch 580/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1116 - val_loss: 0.1835\n",
      "Epoch 581/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1116 - val_loss: 0.1833\n",
      "Epoch 582/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1113 - val_loss: 0.1838\n",
      "Epoch 583/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1113 - val_loss: 0.1824\n",
      "Epoch 584/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1111 - val_loss: 0.1836\n",
      "Epoch 585/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1110 - val_loss: 0.1829\n",
      "Epoch 586/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1108 - val_loss: 0.1837\n",
      "Epoch 587/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1108 - val_loss: 0.1832\n",
      "Epoch 588/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1107 - val_loss: 0.1830\n",
      "Epoch 589/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1106 - val_loss: 0.1828\n",
      "Epoch 590/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1104 - val_loss: 0.1830\n",
      "Epoch 591/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1104 - val_loss: 0.1832\n",
      "Epoch 592/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1102 - val_loss: 0.1825\n",
      "Epoch 593/800\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.1101 - val_loss: 0.1828\n",
      "Epoch 594/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.1099 - val_loss: 0.1828\n",
      "Epoch 595/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.1099 - val_loss: 0.1831\n",
      "Epoch 596/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1097 - val_loss: 0.1834\n",
      "Epoch 597/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1097 - val_loss: 0.1835\n",
      "Epoch 598/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1096 - val_loss: 0.1831\n",
      "Epoch 599/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1094 - val_loss: 0.1830\n",
      "Epoch 600/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1094 - val_loss: 0.1825\n",
      "Epoch 601/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1092 - val_loss: 0.1834\n",
      "Epoch 602/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1091 - val_loss: 0.1826\n",
      "Epoch 603/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1090 - val_loss: 0.1825\n",
      "Epoch 604/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1089 - val_loss: 0.1827\n",
      "Epoch 605/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1088 - val_loss: 0.1841\n",
      "Epoch 606/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1089 - val_loss: 0.1826\n",
      "Epoch 607/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1086 - val_loss: 0.1828\n",
      "Epoch 608/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1084 - val_loss: 0.1822\n",
      "Epoch 609/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.1083 - val_loss: 0.1817\n",
      "Epoch 610/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1083 - val_loss: 0.1823\n",
      "Epoch 611/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1080 - val_loss: 0.1826\n",
      "Epoch 612/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1080 - val_loss: 0.1824\n",
      "Epoch 613/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1080 - val_loss: 0.1821\n",
      "Epoch 614/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1078 - val_loss: 0.1818\n",
      "Epoch 615/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1077 - val_loss: 0.1834\n",
      "Epoch 616/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1077 - val_loss: 0.1828\n",
      "Epoch 617/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1075 - val_loss: 0.1830\n",
      "Epoch 618/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1075 - val_loss: 0.1822\n",
      "Epoch 619/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1073 - val_loss: 0.1822\n",
      "Epoch 620/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1071 - val_loss: 0.1823\n",
      "Epoch 621/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1071 - val_loss: 0.1822\n",
      "Epoch 622/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1069 - val_loss: 0.1819\n",
      "Epoch 623/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1068 - val_loss: 0.1816\n",
      "Epoch 624/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1068 - val_loss: 0.1823\n",
      "Epoch 625/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1067 - val_loss: 0.1814\n",
      "Epoch 626/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1066 - val_loss: 0.1822\n",
      "Epoch 627/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1064 - val_loss: 0.1823\n",
      "Epoch 628/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1065 - val_loss: 0.1826\n",
      "Epoch 629/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1062 - val_loss: 0.1820\n",
      "Epoch 630/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1061 - val_loss: 0.1823\n",
      "Epoch 631/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1060 - val_loss: 0.1822\n",
      "Epoch 632/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1059 - val_loss: 0.1821\n",
      "Epoch 633/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1058 - val_loss: 0.1824\n",
      "Epoch 634/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1058 - val_loss: 0.1824\n",
      "Epoch 635/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1056 - val_loss: 0.1820\n",
      "Epoch 636/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1054 - val_loss: 0.1830\n",
      "Epoch 637/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1056 - val_loss: 0.1818\n",
      "Epoch 638/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1053 - val_loss: 0.1813\n",
      "Epoch 639/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1052 - val_loss: 0.1812\n",
      "Epoch 640/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1050 - val_loss: 0.1816\n",
      "Epoch 641/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1050 - val_loss: 0.1824\n",
      "Epoch 642/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1049 - val_loss: 0.1816\n",
      "Epoch 643/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1048 - val_loss: 0.1822\n",
      "Epoch 644/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1047 - val_loss: 0.1821\n",
      "Epoch 645/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1046 - val_loss: 0.1820\n",
      "Epoch 646/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1046 - val_loss: 0.1820\n",
      "Epoch 647/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1044 - val_loss: 0.1825\n",
      "Epoch 648/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1042 - val_loss: 0.1815\n",
      "Epoch 649/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1042 - val_loss: 0.1813\n",
      "Epoch 650/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1040 - val_loss: 0.1832\n",
      "Epoch 651/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1043 - val_loss: 0.1825\n",
      "Epoch 652/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1040 - val_loss: 0.1811\n",
      "Epoch 653/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1037 - val_loss: 0.1822\n",
      "Epoch 654/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1037 - val_loss: 0.1817\n",
      "Epoch 655/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1036 - val_loss: 0.1817\n",
      "Epoch 656/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1034 - val_loss: 0.1806\n",
      "Epoch 657/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1033 - val_loss: 0.1816\n",
      "Epoch 658/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1035 - val_loss: 0.1822\n",
      "Epoch 659/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1033 - val_loss: 0.1806\n",
      "Epoch 660/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.1030 - val_loss: 0.1818\n",
      "Epoch 661/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1029 - val_loss: 0.1813\n",
      "Epoch 662/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1029 - val_loss: 0.1809\n",
      "Epoch 663/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1028 - val_loss: 0.1807\n",
      "Epoch 664/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1026 - val_loss: 0.1810\n",
      "Epoch 665/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1026 - val_loss: 0.1815\n",
      "Epoch 666/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1026 - val_loss: 0.1810\n",
      "Epoch 667/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1023 - val_loss: 0.1811\n",
      "Epoch 668/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1023 - val_loss: 0.1809\n",
      "Epoch 669/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1023 - val_loss: 0.1805\n",
      "Epoch 670/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1021 - val_loss: 0.1815\n",
      "Epoch 671/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1019 - val_loss: 0.1811\n",
      "Epoch 672/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1019 - val_loss: 0.1805\n",
      "Epoch 673/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1018 - val_loss: 0.1812\n",
      "Epoch 674/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1016 - val_loss: 0.1806\n",
      "Epoch 675/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1016 - val_loss: 0.1815\n",
      "Epoch 676/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1015 - val_loss: 0.1810\n",
      "Epoch 677/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1013 - val_loss: 0.1807\n",
      "Epoch 678/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1014 - val_loss: 0.1812\n",
      "Epoch 679/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1012 - val_loss: 0.1814\n",
      "Epoch 680/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1011 - val_loss: 0.1812\n",
      "Epoch 681/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1010 - val_loss: 0.1808\n",
      "Epoch 682/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1010 - val_loss: 0.1805\n",
      "Epoch 683/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1008 - val_loss: 0.1808\n",
      "Epoch 684/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1008 - val_loss: 0.1800\n",
      "Epoch 685/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.1006 - val_loss: 0.1808\n",
      "Epoch 686/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1006 - val_loss: 0.1809\n",
      "Epoch 687/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1005 - val_loss: 0.1811\n",
      "Epoch 688/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.1004 - val_loss: 0.1804\n",
      "Epoch 689/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1002 - val_loss: 0.1810\n",
      "Epoch 690/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1002 - val_loss: 0.1800\n",
      "Epoch 691/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.1001 - val_loss: 0.1809\n",
      "Epoch 692/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.1000 - val_loss: 0.1806\n",
      "Epoch 693/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0998 - val_loss: 0.1803\n",
      "Epoch 694/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0998 - val_loss: 0.1798\n",
      "Epoch 695/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0996 - val_loss: 0.1803\n",
      "Epoch 696/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0997 - val_loss: 0.1807\n",
      "Epoch 697/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0995 - val_loss: 0.1811\n",
      "Epoch 698/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0994 - val_loss: 0.1803\n",
      "Epoch 699/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0993 - val_loss: 0.1805\n",
      "Epoch 700/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0993 - val_loss: 0.1806\n",
      "Epoch 701/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0992 - val_loss: 0.1805\n",
      "Epoch 702/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0991 - val_loss: 0.1802\n",
      "Epoch 703/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0989 - val_loss: 0.1804\n",
      "Epoch 704/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0989 - val_loss: 0.1807\n",
      "Epoch 705/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0987 - val_loss: 0.1802\n",
      "Epoch 706/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0986 - val_loss: 0.1808\n",
      "Epoch 707/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0986 - val_loss: 0.1799\n",
      "Epoch 708/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0986 - val_loss: 0.1796\n",
      "Epoch 709/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0984 - val_loss: 0.1802\n",
      "Epoch 710/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0983 - val_loss: 0.1808\n",
      "Epoch 711/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0983 - val_loss: 0.1801\n",
      "Epoch 712/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0981 - val_loss: 0.1811\n",
      "Epoch 713/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0981 - val_loss: 0.1800\n",
      "Epoch 714/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0980 - val_loss: 0.1805\n",
      "Epoch 715/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0978 - val_loss: 0.1796\n",
      "Epoch 716/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0978 - val_loss: 0.1804\n",
      "Epoch 717/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0976 - val_loss: 0.1803\n",
      "Epoch 718/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0976 - val_loss: 0.1808\n",
      "Epoch 719/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0974 - val_loss: 0.1794\n",
      "Epoch 720/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0974 - val_loss: 0.1809\n",
      "Epoch 721/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0973 - val_loss: 0.1802\n",
      "Epoch 722/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0973 - val_loss: 0.1795\n",
      "Epoch 723/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0971 - val_loss: 0.1794\n",
      "Epoch 724/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0971 - val_loss: 0.1799\n",
      "Epoch 725/800\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0970 - val_loss: 0.1793\n",
      "Epoch 726/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0969 - val_loss: 0.1796\n",
      "Epoch 727/800\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0967 - val_loss: 0.1805\n",
      "Epoch 728/800\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0967 - val_loss: 0.1799\n",
      "Epoch 729/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0965 - val_loss: 0.1801\n",
      "Epoch 730/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0965 - val_loss: 0.1805\n",
      "Epoch 731/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0964 - val_loss: 0.1795\n",
      "Epoch 732/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0963 - val_loss: 0.1804\n",
      "Epoch 733/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0964 - val_loss: 0.1795\n",
      "Epoch 734/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0961 - val_loss: 0.1809\n",
      "Epoch 735/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0963 - val_loss: 0.1797\n",
      "Epoch 736/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0960 - val_loss: 0.1802\n",
      "Epoch 737/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0959 - val_loss: 0.1797\n",
      "Epoch 738/800\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0957 - val_loss: 0.1792\n",
      "Epoch 739/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0957 - val_loss: 0.1804\n",
      "Epoch 740/800\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0957 - val_loss: 0.1802\n",
      "Epoch 741/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0955 - val_loss: 0.1797\n",
      "Epoch 742/800\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0954 - val_loss: 0.1790\n",
      "Epoch 743/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0954 - val_loss: 0.1801\n",
      "Epoch 744/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0953 - val_loss: 0.1796\n",
      "Epoch 745/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0952 - val_loss: 0.1791\n",
      "Epoch 746/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0951 - val_loss: 0.1796\n",
      "Epoch 747/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0951 - val_loss: 0.1795\n",
      "Epoch 748/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0949 - val_loss: 0.1802\n",
      "Epoch 749/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0948 - val_loss: 0.1794\n",
      "Epoch 750/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0948 - val_loss: 0.1806\n",
      "Epoch 751/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0948 - val_loss: 0.1795\n",
      "Epoch 752/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0946 - val_loss: 0.1795\n",
      "Epoch 753/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0945 - val_loss: 0.1789\n",
      "Epoch 754/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0944 - val_loss: 0.1791\n",
      "Epoch 755/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0944 - val_loss: 0.1790\n",
      "Epoch 756/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0943 - val_loss: 0.1788\n",
      "Epoch 757/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0941 - val_loss: 0.1795\n",
      "Epoch 758/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0940 - val_loss: 0.1804\n",
      "Epoch 759/800\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0940 - val_loss: 0.1792\n",
      "Epoch 760/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0939 - val_loss: 0.1793\n",
      "Epoch 761/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0938 - val_loss: 0.1786\n",
      "Epoch 762/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0938 - val_loss: 0.1797\n",
      "Epoch 763/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0937 - val_loss: 0.1794\n",
      "Epoch 764/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0936 - val_loss: 0.1787\n",
      "Epoch 765/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0934 - val_loss: 0.1790\n",
      "Epoch 766/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0934 - val_loss: 0.1794\n",
      "Epoch 767/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0934 - val_loss: 0.1789\n",
      "Epoch 768/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0932 - val_loss: 0.1796\n",
      "Epoch 769/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0931 - val_loss: 0.1784\n",
      "Epoch 770/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0930 - val_loss: 0.1793\n",
      "Epoch 771/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0930 - val_loss: 0.1789\n",
      "Epoch 772/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0929 - val_loss: 0.1796\n",
      "Epoch 773/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0928 - val_loss: 0.1799\n",
      "Epoch 774/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0928 - val_loss: 0.1786\n",
      "Epoch 775/800\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0927 - val_loss: 0.1788\n",
      "Epoch 776/800\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0926 - val_loss: 0.1790\n",
      "Epoch 777/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0924 - val_loss: 0.1785\n",
      "Epoch 778/800\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0924 - val_loss: 0.1796\n",
      "Epoch 779/800\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0923 - val_loss: 0.1792\n",
      "Epoch 780/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0922 - val_loss: 0.1797\n",
      "Epoch 781/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0922 - val_loss: 0.1794\n",
      "Epoch 782/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0920 - val_loss: 0.1792\n",
      "Epoch 783/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0921 - val_loss: 0.1789\n",
      "Epoch 784/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0919 - val_loss: 0.1797\n",
      "Epoch 785/800\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0919 - val_loss: 0.1791\n",
      "Epoch 786/800\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0917 - val_loss: 0.1784\n",
      "Epoch 787/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0917 - val_loss: 0.1797\n",
      "Epoch 788/800\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0916 - val_loss: 0.1790\n",
      "Epoch 789/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0915 - val_loss: 0.1785\n",
      "Epoch 790/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0914 - val_loss: 0.1802\n",
      "Epoch 791/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0916 - val_loss: 0.1789\n",
      "Epoch 792/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0913 - val_loss: 0.1788\n",
      "Epoch 793/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0913 - val_loss: 0.1789\n",
      "Epoch 794/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0913 - val_loss: 0.1786\n",
      "Epoch 795/800\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0910 - val_loss: 0.1782\n",
      "Epoch 796/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0910 - val_loss: 0.1795\n",
      "Epoch 797/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0910 - val_loss: 0.1788\n",
      "Epoch 798/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0909 - val_loss: 0.1791\n",
      "Epoch 799/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0907 - val_loss: 0.1782\n",
      "Epoch 800/800\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0906 - val_loss: 0.1787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d794c2e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_val,y_train,y_val = prepare_logistic(input_type = \"rgb\",\n",
    "                                                X_rgb_train = X_rgb_train,y_train =y_train, \n",
    "                                                X_rgb_val=X_rgb_val, y_val=y_val)\n",
    "                                                \n",
    "# one vs all multiclass classifier, print binary loss along the way     \n",
    "logistic_reg = build_logistic(l2= 1e-8)                                      \n",
    "logistic_reg.fit(X_train,y_train,epochs=800,\n",
    "                    batch_size=500,\n",
    "                    validation_data = (X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With just audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With video + audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate model performance\n",
    "consider tuning learning rate, regularization strength, by looking at F1 score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "gAP = 0.3456, PERR = 0.4241, HIT1 = 0.5939\n",
      "Optimal weigthed F1 score 0.4215 when treshold = 0.7800\n",
      "\n",
      "validation\n",
      "gAP = 0.1102, PERR = 0.3283, HIT1 = 0.4769\n",
      "Optimal weigthed F1 score 0.2909 when treshold = 0.0200\n",
      "gAP = 0.1102, PERR = 0.3283, HIT1 = 0.4769\n",
      "Weigthed F1 score 0.2850 when treshold = 0.7800\n",
      "\n",
      "test\n",
      "gAP = 0.0952, PERR = 0.2996, HIT1 = 0.4783\n",
      "Optimal weigthed F1 score 0.2834 when treshold = 0.4300\n",
      "gAP = 0.0952, PERR = 0.2996, HIT1 = 0.4783\n",
      "Weigthed F1 score 0.2749 when treshold = 0.7800\n"
     ]
    }
   ],
   "source": [
    "import eval_util as eval\n",
    "from report import report_performance,make_top_n_pred_df,get_label\n",
    "\n",
    "print(\"training\")\n",
    "y_predproba_train = logistic_reg.predict(X_train)\n",
    "gAP_train,PERR_train, HIT1_train,F1_optimal_train,thresh_optimal_train = report_performance(y_predproba_train,y_train,verbose=True, thresh_step=0.01,thresh=None)\n",
    "\n",
    "print(\"\\nvalidation\")\n",
    "y_predproba_val = logistic_reg.predict(X_val)\n",
    "gAP_val,PERR_val, HIT1_val,F1_optimal_val,thresh_optimal_val = report_performance(y_predproba_val,y_val,verbose=True, thresh_step=0.01)\n",
    "gAP_val,PERR_val, HIT1_val,F1_val= report_performance(y_predproba_val,y_val,verbose=True, thresh=thresh_optimal_train)\n",
    "\n",
    "print(\"\\ntest\")\n",
    "X_test = X_rgb_test\n",
    "y_predproba_test = logistic_reg.predict(X_test)\n",
    "y_predproba_test = logistic_reg.predict(X_test)\n",
    "gAP_val,PERR_test, HIT1_val,F1_optimal_test,thresh_optimal_test= report_performance(y_predproba_test,y_test)\n",
    "gAP_val,PERR_test, HIT1_test,F1_test= report_performance(y_predproba_test,y_test,verbose=True, thresh=thresh_optimal_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudo_id</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_predproba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA8l</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[3.8626872916723435e-17, 2.948607131434357e-23...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fx8l</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1.9990340850016678e-32, 3.1517587747564163e-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8s8l</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2.9847021778550697e-06, 1.2619893906197933e-1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x48l</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[5.172878659166595e-14, 1.6292141247209457e-12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP8l</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, ...</td>\n",
       "      <td>[6.187164929699618e-12, 2.0612565473920874e-12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pseudo_id                                             y_true  \\\n",
       "0      PA8l  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1      fx8l  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2      8s8l  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3      x48l  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4      HP8l  [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, ...   \n",
       "\n",
       "                                         y_predproba  \n",
       "0  [3.8626872916723435e-17, 2.948607131434357e-23...  \n",
       "1  [1.9990340850016678e-32, 3.1517587747564163e-1...  \n",
       "2  [2.9847021778550697e-06, 1.2619893906197933e-1...  \n",
       "3  [5.172878659166595e-14, 1.6292141247209457e-12...  \n",
       "4  [6.187164929699618e-12, 2.0612565473920874e-12...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### raw version\n",
    "pred_df_raw = pd.DataFrame({\"pseudo_id\": feat_pseudoid_test,\n",
    "                            \"y_true\":tf.cast(y_test,tf.int32).numpy().tolist(),\n",
    "                            \"y_predproba\":y_predproba_test.tolist()})\n",
    "pred_df_raw.to_pickle('logistic_video_rgb_raw.pkl')\n",
    "pred_df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudo_id</th>\n",
       "      <th>label_true</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>predict_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA8l</td>\n",
       "      <td>[89, 201]</td>\n",
       "      <td>[3, 26, 13, 463, 8]</td>\n",
       "      <td>[1.0, 1.0, 0.9999810457229614, 0.0274487733840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fx8l</td>\n",
       "      <td>[15, 277, 400]</td>\n",
       "      <td>[6, 11, 25, 16, 33]</td>\n",
       "      <td>[1.5098697403459482e-08, 1.4216440469283498e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8s8l</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[14, 0, 2, 25, 1]</td>\n",
       "      <td>[0.0004627108573913574, 2.9847021778550697e-06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x48l</td>\n",
       "      <td>[305]</td>\n",
       "      <td>[2, 55, 387, 79, 17]</td>\n",
       "      <td>[1.0, 1.0, 0.9999998211860657, 0.9994552135467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP8l</td>\n",
       "      <td>[4, 10, 13]</td>\n",
       "      <td>[4, 3, 9, 13, 71]</td>\n",
       "      <td>[4.525904660113156e-05, 3.049834504054161e-06,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tO8l</td>\n",
       "      <td>[0, 12]</td>\n",
       "      <td>[0, 12, 9, 96, 34]</td>\n",
       "      <td>[1.0, 1.0, 1.3159846275812015e-05, 1.481507894...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HL8l</td>\n",
       "      <td>[21, 23, 24, 73, 504]</td>\n",
       "      <td>[24, 73, 23, 21, 956]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.99940025806427]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>er8l</td>\n",
       "      <td>[0, 1, 139]</td>\n",
       "      <td>[0, 36, 12, 6, 112]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.9998304843902588, 0.03641775...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LH8l</td>\n",
       "      <td>[6]</td>\n",
       "      <td>[964, 6, 8, 25, 3]</td>\n",
       "      <td>[1.0, 1.0, 0.9999704360961914, 0.1540841460227...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>h88l</td>\n",
       "      <td>[48, 258, 2162]</td>\n",
       "      <td>[278, 35, 41, 43, 44]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pseudo_id             label_true             label_pred  \\\n",
       "0      PA8l              [89, 201]    [3, 26, 13, 463, 8]   \n",
       "1      fx8l         [15, 277, 400]    [6, 11, 25, 16, 33]   \n",
       "2      8s8l                   [25]      [14, 0, 2, 25, 1]   \n",
       "3      x48l                  [305]   [2, 55, 387, 79, 17]   \n",
       "4      HP8l            [4, 10, 13]      [4, 3, 9, 13, 71]   \n",
       "5      tO8l                [0, 12]     [0, 12, 9, 96, 34]   \n",
       "6      HL8l  [21, 23, 24, 73, 504]  [24, 73, 23, 21, 956]   \n",
       "7      er8l            [0, 1, 139]    [0, 36, 12, 6, 112]   \n",
       "8      LH8l                    [6]     [964, 6, 8, 25, 3]   \n",
       "9      h88l        [48, 258, 2162]  [278, 35, 41, 43, 44]   \n",
       "\n",
       "                                       predict_proba  \n",
       "0  [1.0, 1.0, 0.9999810457229614, 0.0274487733840...  \n",
       "1  [1.5098697403459482e-08, 1.4216440469283498e-0...  \n",
       "2  [0.0004627108573913574, 2.9847021778550697e-06...  \n",
       "3  [1.0, 1.0, 0.9999998211860657, 0.9994552135467...  \n",
       "4  [4.525904660113156e-05, 3.049834504054161e-06,...  \n",
       "5  [1.0, 1.0, 1.3159846275812015e-05, 1.481507894...  \n",
       "6             [1.0, 1.0, 1.0, 1.0, 0.99940025806427]  \n",
       "7  [1.0, 1.0, 1.0, 0.9998304843902588, 0.03641775...  \n",
       "8  [1.0, 1.0, 0.9999704360961914, 0.1540841460227...  \n",
       "9                          [1.0, 1.0, 1.0, 1.0, 1.0]  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = make_top_n_pred_df(feat_pseudoid_test,y_predproba_test,feat_labels_test,top_n_pred =5,get_names=False)\n",
    "pred_df.to_pickle('logistic_video_rgb.pkl')\n",
    "pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudo_id</th>\n",
       "      <th>label_true</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>predict_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PA8l</td>\n",
       "      <td>[89, 201]</td>\n",
       "      <td>[3, 26, 13, 463, 8]</td>\n",
       "      <td>[1.0, 1.0, 0.9999810457229614, 0.0274487733840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fx8l</td>\n",
       "      <td>[15, 277, 400]</td>\n",
       "      <td>[6, 11, 25, 16, 33]</td>\n",
       "      <td>[1.5098697403459482e-08, 1.4216440469283498e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8s8l</td>\n",
       "      <td>[25]</td>\n",
       "      <td>[14, 0, 2, 25, 1]</td>\n",
       "      <td>[0.0004627108573913574, 2.9847021778550697e-06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x48l</td>\n",
       "      <td>[305]</td>\n",
       "      <td>[2, 55, 387, 79, 17]</td>\n",
       "      <td>[1.0, 1.0, 0.9999998211860657, 0.9994552135467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP8l</td>\n",
       "      <td>[4, 10, 13]</td>\n",
       "      <td>[4, 3, 9, 13, 71]</td>\n",
       "      <td>[4.525904660113156e-05, 3.049834504054161e-06,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2O8l</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>[4, 3, 13, 9, 6]</td>\n",
       "      <td>[1.0, 0.9999977946281433, 2.437684997858014e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>LG8l</td>\n",
       "      <td>[2, 18, 43, 59, 60, 76]</td>\n",
       "      <td>[6, 18, 43, 19, 2]</td>\n",
       "      <td>[0.0035650432109832764, 6.222427600732772e-06,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>8n8l</td>\n",
       "      <td>[39, 121, 156, 338]</td>\n",
       "      <td>[39, 202, 31, 35, 121]</td>\n",
       "      <td>[1.0, 0.9999967813491821, 0.909619152545929, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>if8l</td>\n",
       "      <td>[2, 30]</td>\n",
       "      <td>[0, 8, 14, 6, 2]</td>\n",
       "      <td>[1.010332373319045e-10, 2.0133398420663084e-11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>XC8l</td>\n",
       "      <td>[5, 16]</td>\n",
       "      <td>[311, 33, 9, 219, 16]</td>\n",
       "      <td>[0.9998970031738281, 0.9960154294967651, 0.000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>276 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    pseudo_id               label_true              label_pred  \\\n",
       "0        PA8l                [89, 201]     [3, 26, 13, 463, 8]   \n",
       "1        fx8l           [15, 277, 400]     [6, 11, 25, 16, 33]   \n",
       "2        8s8l                     [25]       [14, 0, 2, 25, 1]   \n",
       "3        x48l                    [305]    [2, 55, 387, 79, 17]   \n",
       "4        HP8l              [4, 10, 13]       [4, 3, 9, 13, 71]   \n",
       "..        ...                      ...                     ...   \n",
       "271      2O8l                   [3, 4]        [4, 3, 13, 9, 6]   \n",
       "272      LG8l  [2, 18, 43, 59, 60, 76]      [6, 18, 43, 19, 2]   \n",
       "273      8n8l      [39, 121, 156, 338]  [39, 202, 31, 35, 121]   \n",
       "274      if8l                  [2, 30]        [0, 8, 14, 6, 2]   \n",
       "275      XC8l                  [5, 16]   [311, 33, 9, 219, 16]   \n",
       "\n",
       "                                         predict_proba  \n",
       "0    [1.0, 1.0, 0.9999810457229614, 0.0274487733840...  \n",
       "1    [1.5098697403459482e-08, 1.4216440469283498e-0...  \n",
       "2    [0.0004627108573913574, 2.9847021778550697e-06...  \n",
       "3    [1.0, 1.0, 0.9999998211860657, 0.9994552135467...  \n",
       "4    [4.525904660113156e-05, 3.049834504054161e-06,...  \n",
       "..                                                 ...  \n",
       "271  [1.0, 0.9999977946281433, 2.437684997858014e-0...  \n",
       "272  [0.0035650432109832764, 6.222427600732772e-06,...  \n",
       "273  [1.0, 0.9999967813491821, 0.909619152545929, 0...  \n",
       "274  [1.010332373319045e-10, 2.0133398420663084e-11...  \n",
       "275  [0.9998970031738281, 0.9960154294967651, 0.000...  \n",
       "\n",
       "[276 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df_name = make_top_n_pred_df(feat_pseudoid_test,y_predproba_test,feat_labels_test,top_n_pred =5,get_names=True)\n",
    "pred_df_name.head(10)\n",
    "pred_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36ee4a736f0b91ef898179c83c0a5086350074d7c561bc44505fde850b12c59"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ids705')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
