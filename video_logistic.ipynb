{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from preprocess import get_records, preprocess_for_logistic, read_records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from preprocess import get_records, preprocess_for_logistic, read_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read and preprocess training and validation dataset for average pool, validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"^train.+\\\\.tfrecord$\")\n",
    "train_dir  = \"/Users/shufanxia/Documents/IDS705/Video_Popularity_Prediction/frame-level/\"\n",
    "val_dir = \"/Users/shufanxia/Documents/IDS705/Video_Popularity_Prediction/validation-frame/\"\n",
    "\n",
    "frames_train = get_records(train_dir,\"train\")\n",
    "frames_val = get_records(val_dir,\"validate\")\n",
    "\n",
    "n_labels = 300\n",
    "feat_rgb,feat_audio,feat_puesdoid,feat_labels = read_records(frames_train[:1])\n",
    "X_rgb_train, X_audio_train,y_train = preprocess_for_logistic(feat_rgb,feat_audio,feat_labels,n_labels)\n",
    "\n",
    "feat_rgb_val,feat_audio_val,feat_puesdoid_val,feat_labels_val = read_records(frames_val[:1])\n",
    "X_rgb_val, X_audio_val,y_val = preprocess_for_logistic(feat_rgb_val,feat_audio_val,feat_labels_val,n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline logsitic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_logistic(input_type = \"rgb\", l2= 1e-8,X_rgb_train=None,X_audio_train = None, y_train=None,\n",
    "                     X_rgb_val=None,X_audio_val= None,y_val=None):\n",
    "    # build and train a one vs all multiclass classifier\n",
    "    # choose from three types of inputs\n",
    "    if input_type == \"rgb\":\n",
    "        X_train = X_rgb_train\n",
    "        X_val = X_rgb_val\n",
    "    elif input_type == \"audio\":\n",
    "        X_train = X_audio_train\n",
    "        X_val = X_audio_val\n",
    "    elif input_type == \"both\":\n",
    "        X_train = tf.concat([X_rgb_train, X_audio_train],1)\n",
    "        X_val = tf.concat([X_rgb_val, X_audio_val],1)\n",
    "    else:\n",
    "        print(\"invalid input type\")\n",
    "        raise ValueError\n",
    "    print(len(X_train))\n",
    "    logistic_reg = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(n_labels, activation='sigmoid',\n",
    "                            kernel_regularizer=tf.keras.regularizers.L2(l2))\n",
    "                ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD()\n",
    "    logistic_reg.compile(optimizer,\n",
    "                loss=tf.keras.losses.BinaryCrossentropy())\n",
    "    # one vs all multiclass classifier, print binary loss along the way\n",
    "\n",
    "    # randomzie befor training\n",
    "    indices = tf.range(start=0, limit=tf.shape(X_train)[0], dtype=tf.int32)\n",
    "    # train, print training loss and validation loss after each epoch\n",
    "    logistic_reg.fit(X_train,y_train,epochs=10,\n",
    "                    batch_size=500,\n",
    "                    validation_data = (X_val,y_val))\n",
    "\n",
    "    return X_train,X_val,y_train,y_val, logistic_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With just rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 33.8826 - val_loss: 2.0219\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.9397 - val_loss: 1.5565\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5508 - val_loss: 1.4893\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5076 - val_loss: 1.4590\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.3787 - val_loss: 1.5467\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4384 - val_loss: 1.4349\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3309 - val_loss: 1.7304\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5595 - val_loss: 1.3840\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3546 - val_loss: 1.3481\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2673 - val_loss: 1.4493\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.3697 - val_loss: 1.5417\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3722 - val_loss: 1.4315\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3050 - val_loss: 1.2341\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1880 - val_loss: 1.3315\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2204 - val_loss: 1.3709\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2636 - val_loss: 1.1761\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1033 - val_loss: 1.3741\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.2608 - val_loss: 1.2277\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0993 - val_loss: 1.3049\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1986 - val_loss: 1.1711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4ff7c40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_val,y_train,y_val, logistic_reg = prepare_logistic(input_type = \"rgb\",l2= 1e-8,\n",
    "                                                X_rgb_train = X_rgb_train,y_train =y_train, \n",
    "                                                X_rgb_val=X_rgb_val, y_val=y_val)\n",
    "logistic_reg.fit(X_train,y_train,epochs=10,\n",
    "                    batch_size=500,\n",
    "                    validation_data = (X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With just audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "1015\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 30.1254 - val_loss: 2.8566\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2.3450 - val_loss: 1.0727\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1485 - val_loss: 0.9241\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0021 - val_loss: 0.8496\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9250 - val_loss: 0.8081\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8797 - val_loss: 0.7853\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8514 - val_loss: 0.7698\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8296 - val_loss: 0.7550\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.8098 - val_loss: 0.7580\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8013 - val_loss: 0.7353\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.7845 - val_loss: 0.7280\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7763 - val_loss: 0.7260\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7721 - val_loss: 0.7213\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7638 - val_loss: 0.7166\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7577 - val_loss: 0.7137\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7544 - val_loss: 0.7099\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7506 - val_loss: 0.7095\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7485 - val_loss: 0.7097\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7445 - val_loss: 0.7117\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.7418 - val_loss: 0.7069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf133820>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,X_val,y_train,y_val, logistic_reg = prepare_logistic(input_type = \"audio\",l2= 1e-8,\n",
    "                                                X_audio_train =X_audio_train,y_train =y_train, \n",
    "                                                X_audio_val= X_audio_val,y_val=y_val)\n",
    "logistic_reg.fit(X_train,y_train,epochs=10,\n",
    "                    batch_size=500,\n",
    "                    validation_data = (X_val,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With video + audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 23.9635 - val_loss: 1.8920\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.9380 - val_loss: 1.8908\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.9046 - val_loss: 1.8283\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.7635 - val_loss: 1.7190\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.6806 - val_loss: 1.6464\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.6094 - val_loss: 1.8054\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.7806 - val_loss: 1.5585\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.6333 - val_loss: 1.4521\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4002 - val_loss: 1.6514\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.6352 - val_loss: 1.4508\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 1.4975 - val_loss: 1.6726\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5169 - val_loss: 1.5544\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5328 - val_loss: 1.5012\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4527 - val_loss: 1.2976\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4245 - val_loss: 1.1702\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1875 - val_loss: 1.1732\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1724 - val_loss: 1.4582\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4087 - val_loss: 1.6280\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5626 - val_loss: 1.6348\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4848 - val_loss: 1.3115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bf255210>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train,X_val,y_train,y_val, logistic_reg = prepare_logistic(input_type = \"both\",l2= 1e-8,\n",
    "                                                        X_rgb_train = X_rgb_train,X_audio_train =X_audio_train, y_train =y_train,  \n",
    "                                                            X_rgb_val=X_rgb_val, X_audio_val=X_audio_val,  y_val=y_val,)\n",
    "logistic_reg.fit(X_train,y_train,epochs=10,\n",
    "                    batch_size=500,\n",
    "                    validation_data = (X_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert 0.0 to EagerTensor of dtype bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/shufanxia/Documents/YouTube-8m-Classification/video_logistic.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shufanxia/Documents/YouTube-8m-Classification/video_logistic.ipynb#ch0000011?line=4'>5</a>\u001b[0m y_train2  \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(y_train,tf\u001b[39m.\u001b[39mint32)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shufanxia/Documents/YouTube-8m-Classification/video_logistic.ipynb#ch0000011?line=5'>6</a>\u001b[0m gAP_train \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m\u001b[39m.\u001b[39mcalculate_gap(y_predproba_train ,y_train2)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shufanxia/Documents/YouTube-8m-Classification/video_logistic.ipynb#ch0000011?line=6'>7</a>\u001b[0m PERR_train \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_precision_at_equal_recall_rate(y_predproba_train ,y_train)\n",
      "File \u001b[0;32m~/Documents/YouTube-8m-Classification/eval_util.py:64\u001b[0m, in \u001b[0;36mcalculate_precision_at_equal_recall_rate\u001b[0;34m(predictions, actuals)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=61'>62</a>\u001b[0m \u001b[39mfor\u001b[39;00m label_index \u001b[39min\u001b[39;00m top_indices:\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=62'>63</a>\u001b[0m   \u001b[39mif\u001b[39;00m predictions[row][label_index] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=63'>64</a>\u001b[0m     item_precision \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m actuals[row][label_index]\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=64'>65</a>\u001b[0m item_precision \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m top_indices\u001b[39m.\u001b[39msize\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=65'>66</a>\u001b[0m aggregated_precision \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m item_precision\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=152'>153</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=153'>154</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=154'>155</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py?line=103'>104</a>\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py?line=104'>105</a>\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py?line=105'>106</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert 0.0 to EagerTensor of dtype bool"
     ]
    }
   ],
   "source": [
    "import eval_util as eval\n",
    "\n",
    "\n",
    "y_predproba_train = logistic_reg.predict(X_train)\n",
    "y_train2  = tf.cast(y_train,tf.int32)\n",
    "gAP_train = eval.calculate_gap(y_predproba_train ,y_train2)\n",
    "PERR_train = eval.calculate_precision_at_equal_recall_rate(y_predproba_train ,y_train)\n",
    "# HIT1_train= eval.calculate_hit_at_one(y_predproba_train ,y_train)\n",
    "# # f1 score\n",
    "# print(\"Training performance: gAP = %.3f, PERR = %.3f, HIT1 = %.3f\"%(gAP_train,PERR_train, HIT1_train))\n",
    "\n",
    "# y_predproba_val = logistic_reg.predict(X_val)\n",
    "# #gAP_val = eval.calculate_gap(y_predproba_val ,y_val)\n",
    "# #PERR_val = eval.calculate_precision_at_equal_recall_rate(y_predproba_val ,y_val)\n",
    "# HIT1_val= eval.calculate_hit_at_one(y_predproba_val ,y_val)\n",
    "# # f1 score\n",
    "# print(\"Validation performance: gAP = %.3f, PERR = %.3f, HIT1 = %.3f\"%(gAP_val,PERR_val, HIT1_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(322, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predproba_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([322, 300])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n       312, 313, 314, 315, 316, 317, 318, 319, 320, 321])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/shufanxia/Documents/YouTube-8m-Classification/video_logistic.ipynb Cell 15'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shufanxia/Documents/YouTube-8m-Classification/video_logistic.ipynb#ch0000021?line=0'>1</a>\u001b[0m tensor \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcast(y_val, tf\u001b[39m.\u001b[39mbool)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/shufanxia/Documents/YouTube-8m-Classification/video_logistic.ipynb#ch0000021?line=1'>2</a>\u001b[0m HIT1_val\u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m\u001b[39m.\u001b[39;49mcalculate_hit_at_one(y_predproba_val ,tensor)\n",
      "File \u001b[0;32m~/Documents/YouTube-8m-Classification/eval_util.py:39\u001b[0m, in \u001b[0;36mcalculate_hit_at_one\u001b[0;34m(predictions, actuals)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=26'>27</a>\u001b[0m \u001b[39m\"\"\"Performs a local (numpy) calculation of the hit at one.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=27'>28</a>\u001b[0m \n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=28'>29</a>\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=35'>36</a>\u001b[0m \u001b[39m  float: The average hit at one across the entire batch.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=36'>37</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=37'>38</a>\u001b[0m top_prediction \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39margmax(predictions, \u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=38'>39</a>\u001b[0m hits \u001b[39m=\u001b[39m actuals[numpy\u001b[39m.\u001b[39;49marange(actuals\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]), top_prediction]\n\u001b[1;32m     <a href='file:///Users/shufanxia/Documents/YouTube-8m-Classification/eval_util.py?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m numpy\u001b[39m.\u001b[39maverage(hits)\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=152'>153</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=153'>154</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py?line=154'>155</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:889\u001b[0m, in \u001b[0;36m_check_index\u001b[0;34m(idx)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py?line=883'>884</a>\u001b[0m dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(idx, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py?line=884'>885</a>\u001b[0m \u001b[39mif\u001b[39;00m (dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m dtypes\u001b[39m.\u001b[39mas_dtype(dtype) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m _SUPPORTED_SLICE_DTYPES \u001b[39mor\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py?line=885'>886</a>\u001b[0m     idx\u001b[39m.\u001b[39mshape \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(idx\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py?line=886'>887</a>\u001b[0m   \u001b[39m# TODO(slebedev): IndexError seems more appropriate here, but it\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py?line=887'>888</a>\u001b[0m   \u001b[39m# will break `_slice_helper` contract.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/shufanxia/opt/miniconda3/envs/ids705/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py?line=888'>889</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(_SLICE_TYPE_ERROR \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, got \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(idx))\n",
      "\u001b[0;31mTypeError\u001b[0m: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n       312, 313, 314, 315, 316, 317, 318, 319, 320, 321])"
     ]
    }
   ],
   "source": [
    "\n",
    "tensor = tf.cast(y_val, tf.bool)\n",
    "HIT1_val= eval.calculate_hit_at_one(y_predproba_val ,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = pd.read_csv(\"vocabulary.csv\")\n",
    "\n",
    "def get_label(label_index,top_n_labels):\n",
    "  def get_label_row(row):\n",
    "    if type(row)!= np.ndarray:\n",
    "      row= np.array(row)\n",
    "    labels = label_dict.iloc[row[row<top_n_labels]].Name.values\n",
    "    return labels\n",
    "\n",
    "  all_labels  = list(map(lambda row: get_label_row(row), label_index))\n",
    "  return all_labels\n",
    "\n",
    "def make_top_n_pred_df(pesudo_id,y_predproba,feat_labels,top_n = 5):\n",
    "  top_labels_proba = np.fliplr(np.sort(y_predproba,axis=1))[:,:top_n]\n",
    "  top_labels_pred = np.fliplr(y_predproba.argsort(axis=1))[:,:top_n]\n",
    "  label_true = get_label(feat_labels,1000)\n",
    "  label_pred = get_label(top_labels_pred,1000)\n",
    "  predict_df = pd.DataFrame({\"pesudo_id\":pesudo_id,\n",
    "              \"label_true\":label_true,\n",
    "              \"label_pred\":label_pred,\n",
    "              \"predict_proba\":top_labels_proba.tolist()})\n",
    "  return predict_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pesudo_id</th>\n",
       "      <th>label_true</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>predict_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lKbF</td>\n",
       "      <td>[Video game, Racing]</td>\n",
       "      <td>[Drum, Musician, Guitar, Choir, Game]</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.9999840259552002, 0.98466122...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HebF</td>\n",
       "      <td>[Concert, Performance art]</td>\n",
       "      <td>[Musician, Guitar, Dance, Acoustic guitar, Mob...</td>\n",
       "      <td>[1.0, 1.0, 0.008513122797012329, 1.11282688860...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GkbF</td>\n",
       "      <td>[Fashion]</td>\n",
       "      <td>[Musician, Guitar, Acoustic guitar, Associatio...</td>\n",
       "      <td>[1.0, 1.0, 3.8150992622831836e-05, 1.131936855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q2bF</td>\n",
       "      <td>[Music video]</td>\n",
       "      <td>[Musician, Guitar, Fighting game, Acoustic gui...</td>\n",
       "      <td>[1.0, 0.9999983310699463, 0.09486424922943115,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aUbF</td>\n",
       "      <td>[RuneScape, Beach, Sneakers]</td>\n",
       "      <td>[Musician, Game, Dance, Acoustic guitar, Guitar]</td>\n",
       "      <td>[1.0, 0.9147140979766846, 0.6104596853256226, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A9bF</td>\n",
       "      <td>[Vehicle, Motorsport, Piano, Transport, BMW]</td>\n",
       "      <td>[Guitar, Musician, Association football, Fight...</td>\n",
       "      <td>[0.9999978542327881, 0.9999697804450989, 1.657...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52bF</td>\n",
       "      <td>[Trailer (promotion)]</td>\n",
       "      <td>[Musician, Acoustic guitar, Guitar, Dance, Orc...</td>\n",
       "      <td>[1.0, 0.9999675750732422, 7.4926992965629324e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gNbF</td>\n",
       "      <td>[Vehicle, Car]</td>\n",
       "      <td>[Musician, Mobile phone, Acoustic guitar, Guit...</td>\n",
       "      <td>[1.0, 0.018159449100494385, 5.379041340347612e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6ZbF</td>\n",
       "      <td>[Video game, Television, DayZ (video game)]</td>\n",
       "      <td>[Acoustic guitar, Musician, Guitar, Mobile pho...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.14578327536582947, 2.8150027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rubF</td>\n",
       "      <td>[Cosmetics, Fashion]</td>\n",
       "      <td>[Acoustic guitar, Musician, Guitar, First-pers...</td>\n",
       "      <td>[1.0, 1.0, 0.9846801161766052, 2.8657879624915...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pesudo_id                                    label_true  \\\n",
       "0      lKbF                          [Video game, Racing]   \n",
       "1      HebF                    [Concert, Performance art]   \n",
       "2      GkbF                                     [Fashion]   \n",
       "3      q2bF                                 [Music video]   \n",
       "4      aUbF                  [RuneScape, Beach, Sneakers]   \n",
       "5      A9bF  [Vehicle, Motorsport, Piano, Transport, BMW]   \n",
       "6      52bF                         [Trailer (promotion)]   \n",
       "7      gNbF                                [Vehicle, Car]   \n",
       "8      6ZbF   [Video game, Television, DayZ (video game)]   \n",
       "9      rubF                          [Cosmetics, Fashion]   \n",
       "\n",
       "                                          label_pred  \\\n",
       "0              [Drum, Musician, Guitar, Choir, Game]   \n",
       "1  [Musician, Guitar, Dance, Acoustic guitar, Mob...   \n",
       "2  [Musician, Guitar, Acoustic guitar, Associatio...   \n",
       "3  [Musician, Guitar, Fighting game, Acoustic gui...   \n",
       "4   [Musician, Game, Dance, Acoustic guitar, Guitar]   \n",
       "5  [Guitar, Musician, Association football, Fight...   \n",
       "6  [Musician, Acoustic guitar, Guitar, Dance, Orc...   \n",
       "7  [Musician, Mobile phone, Acoustic guitar, Guit...   \n",
       "8  [Acoustic guitar, Musician, Guitar, Mobile pho...   \n",
       "9  [Acoustic guitar, Musician, Guitar, First-pers...   \n",
       "\n",
       "                                       predict_proba  \n",
       "0  [1.0, 1.0, 1.0, 0.9999840259552002, 0.98466122...  \n",
       "1  [1.0, 1.0, 0.008513122797012329, 1.11282688860...  \n",
       "2  [1.0, 1.0, 3.8150992622831836e-05, 1.131936855...  \n",
       "3  [1.0, 0.9999983310699463, 0.09486424922943115,...  \n",
       "4  [1.0, 0.9147140979766846, 0.6104596853256226, ...  \n",
       "5  [0.9999978542327881, 0.9999697804450989, 1.657...  \n",
       "6  [1.0, 0.9999675750732422, 7.4926992965629324e-...  \n",
       "7  [1.0, 0.018159449100494385, 5.379041340347612e...  \n",
       "8  [1.0, 1.0, 1.0, 0.14578327536582947, 2.8150027...  \n",
       "9  [1.0, 1.0, 0.9846801161766052, 2.8657879624915...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_df = make_top_n_pred_df(feat_puesdoid,y_predproba_train,feat_labels,top_n = 5,get_names=True)\n",
    "train_pred_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pesudo_id</th>\n",
       "      <th>label_true</th>\n",
       "      <th>label_pred</th>\n",
       "      <th>predict_proba</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Buay</td>\n",
       "      <td>[Game, Video game, Sports game, Extreme sport]</td>\n",
       "      <td>[Guitar, Musician, Mobile phone, Piano, Perfor...</td>\n",
       "      <td>[1.0, 1.0, 0.3430946469306946, 3.3650237583060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jeay</td>\n",
       "      <td>[Game, Association football, Highlight film]</td>\n",
       "      <td>[Musician, Acoustic guitar, Guitar, Dance, Sma...</td>\n",
       "      <td>[1.0, 0.0006382465362548828, 0.000107368359749...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geay</td>\n",
       "      <td>[Vehicle, Car, Driving]</td>\n",
       "      <td>[Musician, Dance, Guitar, Association football...</td>\n",
       "      <td>[1.0, 0.9999986886978149, 0.9998586177825928, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lSay</td>\n",
       "      <td>[Concert]</td>\n",
       "      <td>[Sedan (automobile), Rail transport, Musician,...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.9999985694885254]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JMay</td>\n",
       "      <td>[Musician, Guitar, String instrument, Acoustic...</td>\n",
       "      <td>[Musician, Acoustic guitar, Guitar, Electric g...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.9999984502792358, 7.50024575...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vEay</td>\n",
       "      <td>[Rail freight transport]</td>\n",
       "      <td>[Guitar, Musician, Super Smash Bros., Railroad...</td>\n",
       "      <td>[1.0, 1.0, 0.9990826845169067, 0.8304609656333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nday</td>\n",
       "      <td>[Game, Association football, Highlight film]</td>\n",
       "      <td>[Musician, Guitar, Game, Acoustic guitar, Smar...</td>\n",
       "      <td>[1.0, 0.9999995827674866, 0.899193525314331, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XBay</td>\n",
       "      <td>[Food, Recipe, Cooking, Cuisine, Dish (food), ...</td>\n",
       "      <td>[Musician, Smartphone, Acoustic guitar, Mobile...</td>\n",
       "      <td>[1.0, 5.69418534723809e-06, 1.4456688859354472...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wgay</td>\n",
       "      <td>[Pet, Dog, Puppy, Sewing]</td>\n",
       "      <td>[Musician, Guitar, Smartphone, Piano, Mobile p...</td>\n",
       "      <td>[1.0, 0.9999997615814209, 8.048542440519668e-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1say</td>\n",
       "      <td>[Food, Disc jockey, Wheelie, Loader (equipment)]</td>\n",
       "      <td>[Musician, Guitar, Toy, Food, Fighting game]</td>\n",
       "      <td>[1.0, 1.0, 2.2412124933701705e-10, 5.725077009...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  pesudo_id                                         label_true  \\\n",
       "0      Buay     [Game, Video game, Sports game, Extreme sport]   \n",
       "1      Jeay       [Game, Association football, Highlight film]   \n",
       "2      Geay                            [Vehicle, Car, Driving]   \n",
       "3      lSay                                          [Concert]   \n",
       "4      JMay  [Musician, Guitar, String instrument, Acoustic...   \n",
       "5      vEay                           [Rail freight transport]   \n",
       "6      Nday       [Game, Association football, Highlight film]   \n",
       "7      XBay  [Food, Recipe, Cooking, Cuisine, Dish (food), ...   \n",
       "8      wgay                          [Pet, Dog, Puppy, Sewing]   \n",
       "9      1say   [Food, Disc jockey, Wheelie, Loader (equipment)]   \n",
       "\n",
       "                                          label_pred  \\\n",
       "0  [Guitar, Musician, Mobile phone, Piano, Perfor...   \n",
       "1  [Musician, Acoustic guitar, Guitar, Dance, Sma...   \n",
       "2  [Musician, Dance, Guitar, Association football...   \n",
       "3  [Sedan (automobile), Rail transport, Musician,...   \n",
       "4  [Musician, Acoustic guitar, Guitar, Electric g...   \n",
       "5  [Guitar, Musician, Super Smash Bros., Railroad...   \n",
       "6  [Musician, Guitar, Game, Acoustic guitar, Smar...   \n",
       "7  [Musician, Smartphone, Acoustic guitar, Mobile...   \n",
       "8  [Musician, Guitar, Smartphone, Piano, Mobile p...   \n",
       "9       [Musician, Guitar, Toy, Food, Fighting game]   \n",
       "\n",
       "                                       predict_proba  \n",
       "0  [1.0, 1.0, 0.3430946469306946, 3.3650237583060...  \n",
       "1  [1.0, 0.0006382465362548828, 0.000107368359749...  \n",
       "2  [1.0, 0.9999986886978149, 0.9998586177825928, ...  \n",
       "3           [1.0, 1.0, 1.0, 1.0, 0.9999985694885254]  \n",
       "4  [1.0, 1.0, 1.0, 0.9999984502792358, 7.50024575...  \n",
       "5  [1.0, 1.0, 0.9990826845169067, 0.8304609656333...  \n",
       "6  [1.0, 0.9999995827674866, 0.899193525314331, 4...  \n",
       "7  [1.0, 5.69418534723809e-06, 1.4456688859354472...  \n",
       "8  [1.0, 0.9999997615814209, 8.048542440519668e-0...  \n",
       "9  [1.0, 1.0, 2.2412124933701705e-10, 5.725077009...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training data\n",
    "val_pred_df = make_top_n_pred_df(feat_puesdoid_val,y_predproba_val,feat_labels_val,top_n = 5,get_names=False)\n",
    "val_pred_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36ee4a736f0b91ef898179c83c0a5086350074d7c561bc44505fde850b12c59"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ids705')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
