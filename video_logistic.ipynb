{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from preprocess import get_records, preprocess_for_logistic, read_records\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read and preprocess training and validation dataset for average pool, validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.compile(\"^train.+\\\\.tfrecord$\")\n",
    "train_dir  = \"/Users/shufanxia/Documents/IDS705/Video_Popularity_Prediction/frame-level/\"\n",
    "val_dir = \"/Users/shufanxia/Documents/IDS705/Video_Popularity_Prediction/validation-frame/\"\n",
    "\n",
    "frames_train = get_records(train_dir,\"train\")\n",
    "frames_val = get_records(val_dir,\"validate\")\n",
    "\n",
    "n_samples = 50\n",
    "n_labels = 300\n",
    "feat_rgb,feat_audio,feat_puesdoid,feat_labels = read_records(frames_train[:1])\n",
    "X_rgb_train, X_audio_train,y_train = preprocess_for_logistic(feat_rgb,feat_audio,feat_labels,n_samples,n_labels)\n",
    "\n",
    "feat_rgb_val,feat_audio_val,feat_puesdoid_val,feat_labels_val = read_records(frames_val[:1])\n",
    "X_rgb_val, X_audio_val,y_val = preprocess_for_logistic(feat_rgb_val,feat_audio_val,feat_labels_val,n_samples,n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline logsitic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_logistic_train(input_type = \"rgb\",bach_size=500, epoch=500, \n",
    "                    l2 = 1e-8, X_rgb_train=None,X_audio_train = None, y_train=None,\n",
    "                     X_rgb_val=None, X_aduio_val= None,y_val=None):\n",
    "    # build and train a one vs all multiclass classifier\n",
    "    # choose from three types of inputs\n",
    "    if input_type == \"rgb\":\n",
    "        X_train = X_rgb_train\n",
    "        X_val = X_rgb_val\n",
    "    elif input_type == \"audio\":\n",
    "        X_train = X_audio_train\n",
    "        X_val = X_audio_val\n",
    "    elif input_type == \"both\":\n",
    "        X_train = tf.concat([X_rgb_train, X_audio_train],1)\n",
    "        X_val = tf.concat([X_rgb_val, X_audio_val],1)\n",
    "    else:\n",
    "        print(\"invalid input type\")\n",
    "        raise ValueError\n",
    "\n",
    "    logistic_reg = tf.keras.models.Sequential([\n",
    "                tf.keras.layers.Dense(n_labels, activation='sigmoid',\n",
    "                            kernel_regularizer=tf.keras.regularizers.L2(l2))\n",
    "                ])\n",
    "\n",
    "    optimizer = tf.keras.optimizers.SGD()\n",
    "    logistic_reg.compile(optimizer,\n",
    "                loss=tf.keras.losses.BinaryCrossentropy())\n",
    "\n",
    "    # randomzie befor training\n",
    "    indices = tf.range(start=0, limit=tf.shape(X_train)[0], dtype=tf.int32)\n",
    "    idx = tf.random.shuffle(indices)\n",
    "    X_train= tf.gather(X_train,idx)\n",
    "    y_train = tf.gather(y_train,idx)\n",
    "    # train, print training loss and validation loss after each epoch\n",
    "    logistic_reg.fit(X_train,y_train,epochs=10,\n",
    "                    batch_size=500,\n",
    "                    validation_data = (X_val,y_val))\n",
    "\n",
    "    return logistic_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With just rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 35.3133 - val_loss: 1.7935\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.6762 - val_loss: 1.5516\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5147 - val_loss: 1.6191\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5241 - val_loss: 1.7683\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 1.6272 - val_loss: 1.7439\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5887 - val_loss: 1.6082\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.4901 - val_loss: 1.2901\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2342 - val_loss: 1.5765\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.4238 - val_loss: 1.3545\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3274 - val_loss: 1.4990\n"
     ]
    }
   ],
   "source": [
    "logistic_reg = build_logistic_train(input_type = \"rgb\",bach_size=500, \n",
    "                            epoch=500, l2 = 1e-8,\n",
    "                            X_rgb_train = X_rgb_train,y_train =y_train,  \n",
    "                            X_rgb_val=X_rgb_val, y_val=y_val,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### With just audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 28.8738 - val_loss: 2.7455\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.3719 - val_loss: 1.1906\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.2624 - val_loss: 0.9688\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.0505 - val_loss: 0.8663\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.9462 - val_loss: 0.8218\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8873 - val_loss: 0.7845\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8505 - val_loss: 0.7573\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.8219 - val_loss: 0.7426\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.7988 - val_loss: 0.7314\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7860 - val_loss: 0.7200\n"
     ]
    }
   ],
   "source": [
    "logistic_reg = build_logistic_train(input_type = \"audio\",bach_size=500, \n",
    "                            epoch=500, l2 = 1e-8,\n",
    "                            X_audio_train =X_audio_train, y_train =y_train,  \n",
    "                            X_aduio_val=X_audio_val,  y_val=y_val,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With video + audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 1s 44ms/step - loss: 31.0875 - val_loss: 1.8518\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.8006 - val_loss: 1.9166\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.9545 - val_loss: 1.8386\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.8075 - val_loss: 2.0121\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.9208 - val_loss: 1.8151\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.7579 - val_loss: 1.6504\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.6201 - val_loss: 1.6150\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.5451 - val_loss: 1.5659\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5329 - val_loss: 1.4487\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.3874 - val_loss: 1.3195\n"
     ]
    }
   ],
   "source": [
    "logistic_reg = build_logistic_train(input_type = \"both\",bach_size=500, \n",
    "                            epoch=500, l2 = 1e-8,\n",
    "                            X_rgb_train = X_rgb_train,X_audio_train =X_audio_train, y_train =y_train,  \n",
    "                            X_rgb_val=X_rgb_val, X_aduio_val=X_audio_val,  y_val=y_val,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 47.7726 - val_loss: 15.5031\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 15.2373 - val_loss: 3.3108\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.2327 - val_loss: 0.6140\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.6127 - val_loss: 0.1186\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1179 - val_loss: 0.0231\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 6.4167e-05 - val_loss: 0.0228\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.6401e-05 - val_loss: 0.0226\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 5.0774e-05 - val_loss: 0.0223\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.6429e-05 - val_loss: 0.0221\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 4.2938e-05 - val_loss: 0.0219\n"
     ]
    }
   ],
   "source": [
    "s = build_logistic_train(X_audio_train,y_train, X_audio_val, y_val,input_type=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36ee4a736f0b91ef898179c83c0a5086350074d7c561bc44505fde850b12c59"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('ids705')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
