{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Frame-Level Models\n",
    " - DBOF(audio, rgb, audio+rgb)\n",
    " - MLP (audio, rgb, audio+rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "import sys, os.path\n",
    "FOLDER = os.path.abspath(os.path.join(os.getcwd() ,\"../\"))\n",
    "metric_dir = (FOLDER+ '/metrics')\n",
    "sys.path.append(metric_dir)\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate\n",
    "from keras.optimizers import adam_v2,gradient_descent_v2\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from time import time\n",
    "import tensorflow as tf\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.metrics import TopKCategoricalAccuracy\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "import wandb\n",
    "from report import report_performance,make_top_n_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the weights and biases website to log our inputs\n",
    "wandb.login()\n",
    "wandb.init(project=\"my-test-project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = pd.read_csv(\"vocabulary.csv\")\n",
    "# sample_frame averages all the frames audio or rgb information\n",
    "def sample_frame(frame_data,n_frame_sample):\n",
    "\n",
    "  rgb_by_vid = list(map(\n",
    "      lambda frames: \n",
    "      np.array(frames)[\n",
    "        np.random.choice(len(frames),size=n_frame_sample)\n",
    "        ],frame_data))\n",
    "\n",
    "  X= np.array(rgb_by_vid)\n",
    "  return(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = '/Users/marlynehakizimana/Documents/SPRING/IDS705/FinalProj/frame/' #path to: train, val, test folders with *tfrecord files\n",
    "def process_records(data,tp='test'):\n",
    "    tfiles = sorted(glob.glob(os.path.join(FOLDER, tp, '*tfrecord')))\n",
    "    \n",
    "    ids,aud,rgbs, lbs = [],[],[],[]\n",
    "    for fn in tfiles :\n",
    "        \n",
    "        for example in tf.data.TFRecordDataset(fn):#.take(500):#tf.python_io.tf_record_iterator(fn):\n",
    "            tf_example = tf.train.SequenceExample()#tf.train.Example.FromString(example)\n",
    "            rt=tf_example.ParseFromString(example.numpy())\n",
    "            yss = np.array(tf_example.context.feature[\"labels\"].int64_list.value)\n",
    "            out = np.zeros(2000).astype(np.int8) #number of classes 1000\n",
    "            rgb=[]\n",
    "            audio=[]\n",
    "            frames=len(tf_example.feature_lists.feature_list['rgb'].feature)\n",
    "            #print(\"long\",len(yss))\n",
    "            if np.sum([True for i in yss if i<=1000])==len(yss):\n",
    "                for y in yss:\n",
    "                    out[y] = 1\n",
    "                for k in range(frames):#np.random.randint(0,,100):\n",
    "                    rgb.append(np.array(tf.io.decode_raw(tf_example.feature_lists.feature_list['rgb'].feature[k].bytes_list.value[0],tf.uint8)))\n",
    "                    audio.append(np.array(tf.io.decode_raw(tf_example.feature_lists.feature_list['audio'].feature[k].bytes_list.value[0],tf.uint8)))\n",
    "                ids.append(tf_example.context.feature[\"id\"].bytes_list.value[0].decode(encoding=\"UTF-8\"))\n",
    "                lbs.append(out)\n",
    "                aud.append(audio)\n",
    "                rgbs.append(rgb)\n",
    "    \n",
    "       \n",
    "    return np.array(ids),np.array(aud), np.array(rgbs), np.array(lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_labels(data, tp='test'):\n",
    "    tfiles = sorted(glob.glob(os.path.join(FOLDER, tp, '*tfrecord')))\n",
    "    ids,ys=[],[]\n",
    "    for fn in tfiles:\n",
    "        \n",
    "        for example in tf.data.TFRecordDataset(fn):#.take(500):\n",
    "            tf_example = tf.train.SequenceExample()\n",
    "            rt=tf_example.ParseFromString(example.numpy())\n",
    "            \n",
    "            yss = tf_example.context.feature[\"labels\"].int64_list.value\n",
    "            if np.sum([True for i in yss if i<=1000])==len(yss):\n",
    "                ids.append(tf_example.context.feature[\"id\"].bytes_list.value[0].decode(encoding=\"UTF-8\"))\n",
    "                ys.append(yss)\n",
    "            \n",
    "    return ys, np.array(ids) # returns original ids \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data for each style of feature\n",
    "def prepare_input(input_type = \"rgb\",X_rgb_train=None,X_audio_train = None, y_train=None,\n",
    "                     X_rgb_val=None,X_audio_val= None,y_val=None):\n",
    "                    if input_type == \"rgb\":\n",
    "                        X_train = X_rgb_train\n",
    "                        X_val = X_rgb_val\n",
    "                    elif input_type == \"audio\":\n",
    "                        X_train = X_audio_train\n",
    "                        X_val = X_audio_val\n",
    "                    elif input_type == \"both\":\n",
    "                        X_train = tf.concat([X_rgb_train, X_audio_train],1)\n",
    "                        X_val = tf.concat([X_rgb_val, X_audio_val],1)\n",
    "                    else:\n",
    "                        print(\"invalid input type\")\n",
    "                        raise ValueError\n",
    "                    return X_train,X_val,y_train,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x1_val, x2_val, y_val = process_records('validation','validation')\n",
    "_, x1_train, x2_train, y_train=process_records('train','train')\n",
    "idx, x1_test, x2_test, y_test=process_records('test','test')\n",
    "ylabels,ids=process_labels('test','test')\n",
    "y_val_labels,ids1=process_labels('validation','validation')\n",
    "\n",
    "x1_val=sample_frame(x1_val,50)\n",
    "x2_val=sample_frame(x2_val,50)\n",
    "x1_train=sample_frame(x1_train,50)\n",
    "x2_train=sample_frame(x2_train,50)\n",
    "x1_test=sample_frame(x1_test,50)\n",
    "x2_test=sample_frame(x2_test,50)\n",
    "X_train,Y_train=[x1_train,x2_train],y_train\n",
    "X_val,Y_val=[x1_val,x2_val],y_val\n",
    "idx,X_test,Y_test,ylabels=idx,[x1_test,x2_test],y_test,ylabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBOF MODEL for RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()\n",
    "wandb.init(project=\"model-classification\", entity=\"marlhakizi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_block(x,n=1024):\n",
    "    x = Dense(n)(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x=GlobalAveragePooling1D(data_format='channels_last',keepdims=False)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    return x\n",
    "def build_mod():\n",
    "    in1 = Input((50,1024), name='x1')\n",
    "    x1 = fc_block(in1)\n",
    "    x=x1\n",
    "    out = Dense(2000, activation='sigmoid', name='output')(x)\n",
    "    model = Model(inputs=[in1], outputs=out)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=wandb.config['learning_rate'])\n",
    "    model.compile(optimizer=opt, loss=wandb.config['loss'],metrics=[{\"Top1 Accuracy\":TopKCategoricalAccuracy(k=1)}])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValLog(Callback):\n",
    "  \"\"\" Custom callback to log validation information\n",
    "  at the end of each training epoch\"\"\"\n",
    "  def __init__(self,X_val,num_log_batches=1):\n",
    "    self.num_batches = num_log_batches\n",
    "    self.X_val=X_val\n",
    "    self.flat_class_names = label_dict.Name[:1000].values\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    x_val,y_val,yval_labels,idx=X_val,y_val,y_val_labels,ids1\n",
    "    val_preds = self.model.predict(x_val)\n",
    "    gAP,PERR, HIT1,F1=report_performance(val_preds,y_val,verbose = True,thresh_step = 0.01,thresh=0.5)\n",
    "    wandb.log({\"Validation GAP\":gAP,\"Validation Hit@1\":HIT1,\"Validation F1-Score\":F1})\n",
    "    pred_df = make_top_n_pred_df(idx,val_preds,yval_labels,top_n_pred =5,get_names=True)\n",
    "    yu=pd.DataFrame({'VideoId':pred_df.pesudo_id,\"True labels\": [str(i) for i in pred_df.label_true],\"Pred labels\":[str(i) for i in pred_df.label_pred],'Confidence':pred_df.predict_proba})\n",
    "    predictions_table = wandb.Table(dataframe = yu)\n",
    "    wandb.run.log({\"validation_dta\" : predictions_table})\n",
    "\n",
    "wandb.config={\n",
    "  \"learning_rate\": 0.01,\n",
    "  \"epochs\": 800,\n",
    "  \"batch_size\": 1000,\n",
    "  \"architecture\": \"Frame_level_pooling\",\n",
    "  \"loss\":'categorical_crossentropy',\n",
    "}\n",
    "model_audio = build_mod()\n",
    "callback = EarlyStopping(monitor='loss', patience=10)\n",
    "X_train,X_val,y_train,y_val=prepare_input(input_type = \"rgb\",X_rgb_train=X_train[1],X_audio_train = X_train[0], y_train=Y_train,\n",
    "                     X_rgb_val=X_val[1],X_audio_val= X_val[0],y_val=Y_val)\n",
    "model_audio.fit(X_train,y_train,epochs=wandb.config['epochs'],batch_size=wandb.config['batch_size'],\n",
    "              validation_data = (X_val,y_val),callbacks=[callback,ValLog(num_log_batches=20,)])\n",
    "loss,accuracy=model_audio.evaluate(X_test[1],Y_test)\n",
    "wandb.log({\"Test HitAt1 Accuracy\": round(accuracy*100,2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_audio.save_weights('weights.h5')\n",
    "model_audio.load_weights('weights.h5')\n",
    "y_predproba_test=model_audio.predict(X_test[1], verbose=1, batch_size=10)\n",
    "gAP_test,PERR_test, HIT1_test,F1_test= report_performance(y_predproba_test,Y_test,verbose=True, thresh=0.5)\n",
    "\n",
    "\n",
    "\n",
    "pred_df = make_top_n_pred_df(ids,y_predproba_test,ylabels,top_n_pred =5,get_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_raw_audio = pd.DataFrame({\"pseudo_id\": ids,\n",
    "                            \"y_true\":tf.cast(Y_test,tf.int32).numpy().tolist(),\n",
    "                            \"y_predproba\":y_predproba_test.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df.to_pickle('data/framelevel_rgb.pkl')\n",
    "# pred_df_raw_audio.to_pickle('data/framelevel_rgb_raw.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBOF MODEL for AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mod():\n",
    "    in1 = Input((50,128), name='x1')\n",
    "    x = fc_block(in1)\n",
    "    out = Dense(2000, activation='sigmoid', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=[in1], outputs=out)\n",
    "    print(model.summary())\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=wandb.config['learning_rate'])\n",
    "    model.compile(optimizer=opt, loss=wandb.config['loss'],metrics=[{\"Top1 Accuracy\":TopKCategoricalAccuracy(k=1)}])\n",
    "    return model\n",
    "\n",
    "wandb.config={\n",
    "  \"learning_rate\": 0.001,\n",
    "  \"epochs\": 800,\n",
    "  \"batch_size\": 1000,\n",
    "  \"architecture\": \"Frame_level_pooling\",\n",
    "  \"loss\":'categorical_crossentropy',\n",
    "}\n",
    "X_train,X_val,y_train,y_val=prepare_input(input_type = \"audio\",X_rgb_train=X_train[1],X_audio_train = X_train[0], y_train=Y_train,\n",
    "                     X_rgb_val=X_val[1],X_audio_val= X_val[0],y_val=Y_val)\n",
    "model_audio = build_mod()\n",
    "callback = EarlyStopping(monitor='loss', patience=10)\n",
    "model_audio.fit(X_train,Y_train,epochs=wandb.config['epochs'],batch_size=wandb.config['batch_size'],\n",
    "              validation_data = (X_val,Y_val),callbacks=[callback,ValLog(X_val,num_log_batches=20,)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_audio.save_weights('weights.h5')\n",
    "model_audio.load_weights('weights.h5')\n",
    "y_predproba_test=model_audio.predict(X_test[0], verbose=1, batch_size=10)\n",
    "gAP_test,PERR_test, HIT1_test,F1_test= report_performance(y_predproba_test,Y_test,verbose=True, thresh=0.5)\n",
    "pred_df = make_top_n_pred_df(ids,y_predproba_test,ylabels,top_n_pred =5,get_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_raw_audio = pd.DataFrame({\"pseudo_id\": ids,\n",
    "                            \"y_true\":tf.cast(Y_test,tf.int32).numpy().tolist(),\n",
    "                            \"y_predproba\":y_predproba_test.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df.to_pickle('data/framelevel_audio.pkl')\n",
    "#pred_df_raw_audio.to_pickle('data/framelevel_audio_raw.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBOF MODEL for RGB+AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mod():\n",
    "    in1 = Input((50,128), name='x1')\n",
    "    x1 = fc_block(in1)\n",
    "    in2 = Input((50,1024), name='x2')\n",
    "    x2 = fc_block(in2)\n",
    "    x = Concatenate(axis=-1)([x1, x2])\n",
    "    out = Dense(2000, activation='sigmoid', name='output')(x)\n",
    "    model = Model(inputs=[in1,in2], outputs=out)\n",
    "    opt = adam_v2.Adam(learning_rate=wandb.config['learning_rate'])\n",
    "    model.compile(optimizer=opt, loss=wandb.config['loss'],metrics=[{\"Top1 Accuracy\":TopKCategoricalAccuracy(k=1)}])\n",
    "    return model\n",
    "\n",
    "X_train,X_val,y_train,y_val=prepare_input(input_type = \"both\",X_rgb_train=X_train[1],X_audio_train = X_train[0], y_train=Y_train,\n",
    "                     X_rgb_val=X_val[1],X_audio_val= X_val[0],y_val=Y_val)\n",
    "model_all = build_mod()\n",
    "callback = EarlyStopping(monitor='val_loss', patience=10,restore_best_weights=True)\n",
    "model_all.fit(X_train,y_train,epochs=wandb.config['epochs'],batch_size=wandb.config['batch_size'],\n",
    "              validation_data = (X_val,y_val),callbacks=[callback,ValLog(X_val,num_log_batches=20)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all.save_weights('weights.h5')\n",
    "model_all.load_weights('weights.h5')\n",
    "y_predproba_test=model_all.predict([X_test[0],X_test[1]], verbose=1, batch_size=10)\n",
    "gAP_test,PERR_test, HIT1_test,F1_test= report_performance(y_predproba_test,Y_test,verbose=True, thresh=0.5)\n",
    "pred_df = make_top_n_pred_df(ids,y_predproba_test,ylabels,top_n_pred =5,get_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_raw_all = pd.DataFrame({\"pseudo_id\": ids,\n",
    "                            \"y_true\":tf.cast(Y_test,tf.int32).numpy().tolist(),\n",
    "                            \"y_predproba\":y_predproba_test.tolist()})\n",
    "#pred_df_raw_all.to_pickle('data/framelevel_all_raw.pkl')\n",
    "#pred_df.to_pickle('data/framelevel_all.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model for AUDIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_pooling(frame_data):\n",
    "    # take avaerge across the frames for each video\n",
    "    avg_rgb_by_vid = list(map(\n",
    "        lambda frames: \n",
    "        np.array(frames).mean(axis=0),frame_data))\n",
    "\n",
    "    X= np.array(avg_rgb_by_vid)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_records(data,tp='test'):\n",
    "    tfiles = sorted(glob.glob(os.path.join(FOLDER, tp, '*tfrecord')))\n",
    "    ids,aud,rgbs, lbs = [],[],[],[]\n",
    "    for fn in tfiles :\n",
    "        for example in tf.data.TFRecordDataset(fn):\n",
    "            tf_example = tf.train.SequenceExample()\n",
    "            rt=tf_example.ParseFromString(example.numpy())\n",
    "            yss = np.array(tf_example.context.feature[\"labels\"].int64_list.value)\n",
    "            out = np.zeros(2000).astype(np.int8) #number of classes 1000\n",
    "            rgb=[]\n",
    "            audio=[]\n",
    "            frames=len(tf_example.feature_lists.feature_list['rgb'].feature)\n",
    "            if np.sum([True for i in yss if i<=1000])==len(yss):\n",
    "                for y in yss:\n",
    "                    out[y] = 1\n",
    "                for k in range(frames):\n",
    "                    rgb.append(np.array(tf.io.decode_raw(tf_example.feature_lists.feature_list['rgb'].feature[k].bytes_list.value[0],tf.uint8)))\n",
    "                    audio.append(np.array(tf.io.decode_raw(tf_example.feature_lists.feature_list['audio'].feature[k].bytes_list.value[0],tf.uint8)))\n",
    "                ids.append(tf_example.context.feature[\"id\"].bytes_list.value[0].decode(encoding=\"UTF-8\"))\n",
    "                lbs.append(out)\n",
    "\n",
    "                aud.append(np.mean(np.array(audio),axis=0))\n",
    "                rgbs.append(np.mean(np.array(rgb),axis=0))\n",
    "    \n",
    "       \n",
    "    return np.array(ids),np.array(aud), np.array(rgbs), np.array(lbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video-level Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, x1_val, x2_val, y_val = process_records('validation','validation')\n",
    "_, x1_train, x2_train, y_train=process_records('train','train')\n",
    "idx, x1_test, x2_test, y_test=process_records('test','test')\n",
    "ylabels,ids=process_labels('test','test')\n",
    "\n",
    "y_val_labels,ids1=process_labels('validation','validation')\n",
    "X_train,Y_train=[x1_train,x2_train],y_train\n",
    "X_val,Y_val=[x1_val,x2_val],y_val\n",
    "idx,X_test,Y_test,ylabels=idx,[x1_test,x2_test],y_test,ylabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "wandb.init(project=\"model-classification\", entity=\"marlhakizi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_block(x, n=4096, d=0.2):\n",
    "    x = Dense(n)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU()(x)\n",
    "    x = Dropout(d)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mod():\n",
    "    in1 = Input((128,), name='x1')\n",
    "    x = fc_block(in1)\n",
    "    x = Dense(1024)(x)\n",
    "    out = Dense(2000, activation='sigmoid', name='output')(x)\n",
    "    model = Model(inputs=[in1], outputs=out)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=wandb.config['learning_rate'])\n",
    "    model.compile(optimizer=opt, loss=wandb.config['loss'],metrics=[{\"Top1 Accuracy\":TopKCategoricalAccuracy(k=1)}])\n",
    "    return model\n",
    "\n",
    "wandb.config={\n",
    "  \"learning_rate\": 0.0001,\n",
    "  \"epochs\": 800,\n",
    "  \"batch_size\": 300,\n",
    "  \"architecture\": \"Frame_level_pooling\",\n",
    "  \"loss\":'categorical_crossentropy',\n",
    "}\n",
    "X_train,X_val,y_train,y_val=prepare_input(input_type = \"rgb\",X_rgb_train=X_train[1],X_audio_train = X_train[0], y_train=Y_train,\n",
    "                     X_rgb_val=X_val[1],X_audio_val= X_val[0],y_val=Y_val)\n",
    "model_dense_audio = build_mod()\n",
    "callback = EarlyStopping(monitor='loss', patience=10)\n",
    "model_dense_audio.fit(X_train,Y_train,epochs=wandb.config['epochs'],batch_size=wandb.config['batch_size'],\n",
    "              validation_data = (X_val,Y_val),callbacks=[callback,ValLog(X_val,num_log_batches=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dense_audio.save_weights('weights.h5')\n",
    "model_dense_audio.load_weights('weights.h5')\n",
    "y_predproba_test=model_dense_audio.predict(X_test[0], verbose=1, batch_size=10)\n",
    "gAP_test,PERR_test, HIT1_test,F1_test= report_performance(y_predproba_test,Y_test,verbose=True, thresh=0.5)\n",
    "pred_df = make_top_n_pred_df(ids,y_predproba_test,ylabels,top_n_pred =5,get_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_raw_all = pd.DataFrame({\"pseudo_id\": ids,\n",
    "                            \"y_true\":tf.cast(Y_test,tf.int32).numpy().tolist(),\n",
    "                            \"y_predproba\":y_predproba_test.tolist()})\n",
    "#pred_df_raw_all.to_pickle('data/framelevel_mlp_audio_raw.pkl')\n",
    "#pred_df.to_pickle('data/framelevel_mlp_audio.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model for RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mod():\n",
    "    in1 = Input((1024,), name='x1')\n",
    "    x = fc_block(in1)\n",
    "    out = Dense(2000, activation='sigmoid', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=[in1], outputs=out)\n",
    "    opt = tf.keras.optimizers.SGD(learning_rate=wandb.config['learning_rate'])\n",
    "    model.compile(optimizer=opt, loss=wandb.config['loss'],metrics=[{\"Top1 Accuracy\":TopKCategoricalAccuracy(k=1)}])\n",
    "    return model\n",
    "\n",
    "wandb.config={\n",
    "  \"learning_rate\": 0.0001,\n",
    "  \"epochs\": 800,\n",
    "  \"batch_size\": 300,\n",
    "  \"architecture\": \"Frame_level_pooling\",\n",
    "  \"loss\":'categorical_crossentropy',\n",
    "}\n",
    "X_train,X_val,y_train,y_val=prepare_input(input_type = \"audio\",X_rgb_train=X_train[1],X_audio_train = X_train[0], y_train=Y_train,\n",
    "                     X_rgb_val=X_val[1],X_audio_val= X_val[0],y_val=Y_val)\n",
    "model_rgb = build_mod()\n",
    "callback = EarlyStopping(monitor='loss', patience=10)\n",
    "model_rgb.fit(X_train,Y_train,epochs=wandb.config['epochs'],batch_size=wandb.config['batch_size'],\n",
    "              validation_data = (X_val,Y_val),callbacks=[callback,ValLog(num_log_batches=20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rgb.save_weights('weights.h5')\n",
    "model_rgb.load_weights('weights.h5')\n",
    "y_predproba_test=model_rgb.predict(X_test[1], verbose=1, batch_size=10)\n",
    "gAP_test,PERR_test, HIT1_test,F1_test= report_performance(y_predproba_test,Y_test,verbose=True, thresh=0.5)\n",
    "pred_df = make_top_n_pred_df(ids,y_predproba_test,ylabels,top_n_pred =5,get_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_raw_all = pd.DataFrame({\"pseudo_id\": ids,\n",
    "                            \"y_true\":tf.cast(Y_test,tf.int32).numpy().tolist(),\n",
    "                            \"y_predproba\":y_predproba_test.tolist()})\n",
    "#pred_df_raw_all.to_pickle('data/framelevel_mlp_rgb_raw.pkl')\n",
    "#pred_df.to_pickle('data/framelevel_mlp_rgb.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Model for AUDIO+RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mod():\n",
    "    in1 = Input((128,))\n",
    "    in2 = Input((1024,))\n",
    "    x = Concatenate(axis=-1)([in1, in2])\n",
    "\n",
    "    x = fc_block(x)\n",
    "    out = Dense(2000, activation='sigmoid', name='output')(x)\n",
    "    \n",
    "    model = Model(inputs=[in1,in2], outputs=out)\n",
    "    opt = gradient_descent_v2.SGD(learning_rate=wandb.config['learning_rate'])\n",
    "    model.compile(optimizer=opt, loss=wandb.config['loss'],metrics=[{\"Top1 Accuracy\":TopKCategoricalAccuracy(k=1)}])\n",
    "    return model\n",
    "\n",
    "wandb.config={\n",
    "  \"learning_rate\": 0.01,\n",
    "  \"epochs\": 800,\n",
    "  \"batch_size\": 300,\n",
    "  \"architecture\": \"Frame_level_pooling\",\n",
    "  \"loss\":tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "}\n",
    "X_train,X_val,y_train,y_val=prepare_input(input_type = \"both\",X_rgb_train=X_train[1],X_audio_train = X_train[0], y_train=Y_train,\n",
    "                     X_rgb_val=X_val[1],X_audio_val= X_val[0],y_val=Y_val)\n",
    "model_all = build_mod()\n",
    "callback = EarlyStopping(monitor='val_loss', patience=10,restore_best_weights=True)\n",
    "model_all.fit(X_train,Y_train,epochs=wandb.config['epochs'],batch_size=wandb.config['batch_size'],\n",
    "              validation_data = (X_val,Y_val),callbacks=[callback,ValLog(X_val,num_log_batches=20)])\n",
    "wandb.log({\"Test HitAt1 Accuracy\": round(accuracy*100,2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_all.save_weights('weights.h5')\n",
    "model_all.load_weights('weights.h5')\n",
    "y_predproba_test=model_all.predict([X_test[0],X_test[1]], verbose=1, batch_size=10)\n",
    "gAP_test,PERR_test, HIT1_test,F1_test= report_performance(y_predproba_test,Y_test,verbose=True, thresh=0.5)\n",
    "pred_df = make_top_n_pred_df(ids,y_predproba_test,ylabels,top_n_pred =5,get_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df_raw_all = pd.DataFrame({\"pseudo_id\": ids,\n",
    "                            \"y_true\":tf.cast(Y_test,tf.int32).numpy().tolist(),\n",
    "                            \"y_predproba\":y_predproba_test.tolist()})\n",
    "# pred_df_raw_all.to_pickle('data/framelevel_mlp_all_raw.pkl')\n",
    "# pred_df.to_pickle('data/framelevel_mlp_all.pkl')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e9f11f49cd656f291f5777c461e4288f6343aeff66d80fd968f2fc2025425e8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
